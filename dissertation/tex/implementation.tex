\section{Modelling Locks with TESLA} \label{sec:locks}

\begin{displaycquote}[p. 1]{anderson_tesla:_2014}
TESLA exposes run-time behaviour using program instrumentation, illuminating
coverage of complex state machines and detecting violations of specifications.
\end{displaycquote}

\textcite{anderson_tesla:_2014} draw attention to the suitability of TELSA for
modelling and verifying \emph{state machines} within a program. In this section,
I describe a set of TESLA assertions that ensure the safe usage of a simple
mutual-exclusion lock---these assertions will act as a running example
throughout the rest of the chapter to provide context to the analyses developed
and demonstrate an application of static analysis to TESLA assertions.

Mutual exclusion locks were chosen as the structure to model in this section
because while the number of states and associated operations is small, the state
machine has properties that are non-trivial to analyse statically.

\subsection{Lock Structure}

The lock structure to be modelled in this section is a simple structure wrapper
around a C11 atomic boolean value, together with a set of functions that operate
on these structures.

\begin{listing}[ht]
  \begin{minted}{c}
  #include <stdatomic.h>
  #include <stdbool.h>

  typedef struct lock_st {
    _Atomic(bool) locked
  } lock_t;

  void lock_init(lock_t *lock) {
    atomic_init(&(lock->locked), false);
  }

  bool lock_acquire(lock_t *lock) {
    bool f = false;
    return atomic_compare_exchange_strong(
            &(lock->locked), &f, true);
  }

  void lock_release(lock_t *lock) {
    lock->locked = false;
  }

  void lock_free(lock_t *lock) {
  }
  \end{minted}
  \caption{Implementation of a mutual exclusion lock with C11 atomics}
  \label{lst:mutex}
\end{listing}

The four operations provided by this interface are initialisation,
deinitialisation (for the given lock implementation this is a no-op, but it may
not be for more complex variants), non-blocking acquisition and release. Lock
acquisition is implemented using atomic compare-and-swap, returning
\mintinline{c}{false} if the lock is being held by another user or \mintinline{c}{true}
if the acquisition was successful.

\subsection{Lock Usage}

Using the non-blocking acquisition function described previously, it is possible
to implement a blocking spin-lock in terms of a lock structure:

\begin{minted}{c}
while(!lock_acquire(lock)) {}
\end{minted}

The usage of the lock structure that I have developed assertions to verify is in
fact this spin-lock (i.e.\ where users of the lock repeatedly attempt to acquire
it, execute their critical section, then release it).

Correct usage of the lock in this way can be summarised informally by a set of
invariants:
\begin{itemize}
  \item Consumers can fail to acquire the lock any number of times
  \item Once the lock is acquired, no more attempts to acquire can be made
  \item The lock is released exactly once after being successfully acquired
\end{itemize}

\subsection{TESLA Assertions}

The properties described previously are well-suited to being expressed as TESLA
assertions---they express temporal relationships between program events (calls
to the functions \mintinline{c}{lock_acquire} and \mintinline{c}{lock_release}).

Expressed as TESLA assertions using the explicit automaton style, the properties
are:
\begin{listing}[ht]
  \begin{minted}{c}
  automaton(acq_rel, lock_t *lock) {
    acquire(lock);
    release(lock);
    tesla_done;
  }

  automaton(acquire, lock_t *lock) {
    optional(ATLEAST(1, lock_acquire(lock) == false));
    lock_acquire(lock) == true;
    tesla_done;
  }

  automaton(release, lock_t *lock) {
    returnfrom(lock_release(lock));
    tesla_done;
  }
  \end{minted}
  \caption{Mutex lock properties expressed using TESLA}
  \label{lst:mutex-tesla}
\end{listing}

Writing \mintinline{c}{optional(ATLEAST(1, ...))} is required to work around a
limitation in the TESLA instrumenter code that prevents
\mintinline{c}{ATLEAST(0, ...)} from compiling. The semantics in both cases are
the same, so this is not a major issue.

\subsection{Performance Overhead}

The lock assertions can be used to provide an example of the performance
overhead imposed by instrumenting code with TESLA (and consequently, the
potential benefits of removing safe assertions at compile time).

\subsubsection{Experimental Setup}

The benchmark code used in this demonstration creates a number of
threads, each of which attempts to sort a randomly chosen interval of a
large shared array. Threads access the array under mutual exclusion,
protected by a lock as described in \autoref{lst:mutex}---this creates
contention on the lock, dependent on the number of executing threads.

A single TESLA assertion is added to the benchmark to assert the correct
usage of the mutual exclusion lock on the shared array. Two versions of
the program are generated---one with the TESLA instrumentation left in
place, and another with the instrumentation elided using the model
checker described in \autoref{sec:checking}. Both versions are compiled
using release build settings.

Both programs were run with the same parameters (threads sort an
interval of size \num{15000} from a larger array of size \num{500000},
and the number of threads was varied from 8 to 40), with results
averaged over 5 runs of the program.

The benchmarks were run on my development machine (Intel Xeon E5-1620
\SI{3.6}{\GHz}, 8 cores, 64GB of RAM) running FreeBSD 11.

\subsubsection{Results}

Before the two benchmark programs are even run, one benefit of removing
instrumentation is clear---the binary with its assertions removed is 25\%
smaller than the instrumented binary (\num{19.1} KiB vs. \num{25.3}
KiB).

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      title={Effect of contention on benchmark runtime},
      width=0.85\textwidth,
      xlabel={No. of Threads},
      ylabel={Runtime (s)},
      xmin=5,xmax=43,
      ymin=0,ymax=70,
      xtick={8,16,24,32,40},
      legend pos=north west,
      ymajorgrids=true,
      grid style=dashed,
      cycle list/Dark2,
    ]
      \addplot+[mark=x]
      table [x =x, y =sy, y error =se]{data/locks_bench.dat};

      \addplot+[mark=x]
      table [x =x, y =iy, y error =ie]{data/locks_bench.dat};
      \legend{Uninstrumented,Instrumented}
    \end{axis}
  \end{tikzpicture}
  \caption{Runtime of instrumented and uninstrumented benchmarks at
  varying levels of lock contention}
  \label{fig:locks-bench}
\end{figure}

The results from running the two benchmark programs as described above
are shown in \autoref{fig:locks-bench}. At low levels of contention
there is little difference between the programs---this is because the
TESLA instrumentation code is only executed during lock acquisition and
releasing. However, at higher levels of contention more time is spent in
the TESLA instrumentation code, and the instrumented version shows a
slowdown relative to the uninstrumented version.

From these results the benefits of performing static analysis on TESLA
assertions can be seen---if the assertions lie on a frequently executed code
path, then a runtime performance improvement is likely. A decrease in
binary size is also likely, even if the assertions are executed only
infrequently.

\section{Hand-Coded Static Analysis} \label{sec:hand-coded}

The first approach taken to static analysis of TESLA assertions was to develop
\textquote{special-cased} assertions that attempt to prove properties only for a
single assertion (in this case, \mintinline{c}{acq_rel}).

Because TESLA assertions describe safety properties of programs, the approach
taken is to examine each individual usage of the assertion in question for
possible \textquote{bad things} that could cause the assertion to fail. If none
are found, then the assertion will always succeed at compile time and the
corresponding instrumentation code can be removed safely.

To implement this analysis, a set of cases in which the invariants described
previously could possibly fail was compiled. Some of the simpler possible safety
violations for \mintinline{c}{acq_rel} are:
\begin{itemize}
  \item Either of the lock interface functions have their address taken
  \item One or both of the functions are not called at all
  \item There is no branch on the result of a call to
  \mintinline{c}{lock_acquire}
\end{itemize}

In order to check that these safety properties are not violated, I implemented a
collection of LLVM \cite{lattner_llvm:_2002} analysis passes that each check a
single safety property. As well as these passes, I implemented a small test
suite of programs that use the lock interface (adapted somewhat to allow for
consistent testing).

\begin{table}[ht]
  \centering
  \begin{tabularx}{\textwidth}{Z | Z}
    \toprule
    \textbf{Test Name} & \textbf{Correct?} \\
    \midrule
    address & No \\
    basic & Yes \\
    basic\_indirect & Yes \\
    more\_usage & No \\
    mult\_acq & No \\
    mult\_rel & No \\
    no\_acq\_rel & No \\
    no\_acq & No \\
    no\_rel & No \\
    one\_acq & No \\
    other & No \\
    rel\_before & No \\
    rel\_before\_indirect & No \\
    \bottomrule
  \end{tabularx}
  \caption{Summary of \mintinline{c}{acq_rel} test programs}
\end{table}

The aim of these test cases is to provide a minimal set of test cases
against which the correctness of the analyses can be checked. Each
potential safety violation identified occurs at least once in the test
suite.

\subsection{Results}

While there are some advantages to writing assertion safety analyses in
this way, it is far from an ideal approach to the problem. The key
problems are:
\begin{description}
  \item[Development Time] Developing the LLVM analysis passes takes a
    long time (even allowing for the time spent developing
    \textquote{infrastructure} code).
  \item[Inflexibility] Even a small change to the assertions being
    analysed can mean a large change to the analysis being applied.
  \item[Duplicate Logic] The assumptions made in the assertions must be
    duplicated and spread across multiple passes.
\end{description}

In order to address these issues, we require a system of analysis that can be
built once \textquote{up front}, can be applied to any TESLA assertions
regardless of the properties that they encode and that does not rely on any
specific knowledge of the assertion being checked.

\section{Formalising TESLA Assertions} \label{sec:formal}

In order to generalise the hand-coded analysis style to arbitrary assertions
(rather than specific instances where the relevant properties and failure
conditions are known ahead of time), it is necessary to define a more abstract
model of the semantics of TESLA assertions and the programs to which they are
applied.

The hand-coded analysis relied on developer-supplied knowledge of the failure
conditions for the assertion being checked, which could then be translated into
analysis passes to be run on the program's intermediate representation.

TESLA assertions \textcquote[p. 3]{anderson_tesla:_2014}{have a natural
expression as finite-state automata that can be mechanically woven into a
program}. However, the exact manner in which these automata are constructed is
only touched upon briefly in the paper. In this section, I provide a formal
translation of TESLA automata into corresponding finite state automata.

The automata constructions given in this section are nondeterministic, with
$\varepsilon$-transitions in some places. It is worth noting the well-known
result that a non-deterministic automaton with $n$ states can always be
converted to an equivalent deterministic automaton with up to $2^n$ states
\cite{rabin_finite_1959}. However, in practice the automata constructed using
the methods described in this section do not experience this exponential
increase in size.

\subsection{Program Events}

As described in \autoref{sec:assertions}, TESLA allows temporal relationships
between function calls or returns, assertion sites and structure field
assignments to be expressed. These events are the \textquote{building blocks}
from which an automaton is constructed.

These events have no recursive structure---they only define a program event to
be matched. As a result, the automata they define are very simple.
\autoref{fig:event-auto} shows the constructed automaton for an arbitrary program event
$e$---it has a single transition from the initial state to the accepting state,
labelled by the event $e$.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (start) [] {$q_0$};
    \node[state,accepting] (end) [right=of start] {$q_1$};
    %\node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \path[->] (start) edge node {$e$} (end);
  \end{tikzpicture}
  \caption{Program event automaton}
  \label{fig:event-auto}
\end{figure}

The structure of this automaton is the same no matter what event $e$ it was
constructed for, and it implicitly captures all the properties $e$ may have
(e.g.\ function name, return value or assertion site location). In
\autoref{sec:checking} I give a full description of how these properties are
used to check properties of a program.

\subsection{Composition}

There are two ways in which TESLA automata may be composed---sequential ordering
and disjunction (corresponding to the concrete syntax \mintinline{c}{TSEQUENCE}
and \mintinline{c}{||} respectively). The TESLA source code does in fact make
reference to a conjunction operation on automata, but it is not fully
implemented.\footnote{The protocol buffer format for assertions makes provision
for the extra boolean operation type, but using it in an assertion is
unsupported.} Assertions of these types have recursive structure (i.e. they
contain other automata), and so their constructed automata are defined as
compositions of other automata.

By convention, sub-automata are shown inside dashed boxes. Accepting states
inside these boxes are the accepting states of the sub-automaton, and dotted
lines indicate transitions that are internal to the subautomaton.

\subsubsection{Sequential Ordering}

The simplest temporal relationship TESLA enforces is sequential ordering
(\textquote{event $a$ happens, then event $b$ happens...}). Sequence assertions
may be repeated, and have attributes specifying the minimum and maximum number
of repetitions that are permitted (with the maximum number being potentially
infinite). Sequences may contain any number of sub-assertions.

The cases where exactly one repetition or an infinite number of repetitions is
allowed are easy to define in terms of the sub-automata. The examples given in
\autoref{fig:seq-one-auto} and \autoref{fig:seq-inf-auto} have two subautomata,
but the construction generalises simply to any number.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below=of start] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [right=of end2] (realend) {$q1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (end2) edge node {$\varepsilon$} (realend);
    \draw[->,out=270,in=90] (end.south) to node[above]{$\varepsilon$} (start2.north);
  \end{tikzpicture}
  \caption{Single repetition sequence automaton}
  \label{fig:seq-one-auto}
\end{figure}

From a single repetition, an automata that can recognise an infinite number is
obtained by adding an $\varepsilon$-transition back from the accepting state to
the initial state.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below=of start] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [right=of end2] (realend) {$q_1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (end2) edge node {$\varepsilon$} (realend);
    \draw[->,out=270,in=90] (end.south) to node[above]{$\varepsilon$} (start2.north);

    \draw[->,looseness=1.2,out=90,in=45] (realend.north) to node[above]{$\varepsilon$} (realstart.north east);
  \end{tikzpicture}
  \caption{Infinite repetition sequence automaton}
  \label{fig:seq-inf-auto}
\end{figure}

If the sequence is not exactly-once or infinite, then a copy of the entire
sequence automaton (as in \autoref{fig:seq-one-auto}) must be constructed for
each repetition. The copies in the valid range (between the minimum and the
maximum number of repetitions) have an $\varepsilon$-transition from their
accepting state to the overall accepting state. As a consequence of this, the
size of the constructed automata is directly proportional to the maximum number
of repetitions (if the maximum is finite).

\subsubsection{Disjunction}

A disjunction automaton will accept if \emph{any} of its subautomata do (i.e.\
it implements logical or over its subautomata), and can therefore be constructed
as shown in \autoref{fig:disj-auto} (again, the diagram shows the case for two
subautomata, but the construction generalises to any number).

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [above right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below right=of realstart] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [above right=of end2] (realend) {$q1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (realstart) edge node[below left] {$\varepsilon$} (start2);
    \path[->] (end) edge node {$\varepsilon$} (realend);
    \path[->] (end2) edge node[below right] {$\varepsilon$} (realend);
  \end{tikzpicture}
  \caption{Disjunction automaton}
  \label{fig:disj-auto}
\end{figure}

\section{Model Checking TESLA} \label{sec:checking}

Previously (in \autoref{sec:formal}) I gave a translation from TESLA assertions
to nondeterministic finite automata with transitions labeled with program event
assertions. This automaton can be seen as a \emph{specification} for a program,
expressed in a form of temporal logic. To check whether a program is correct
with regard to this specification can now be seen as a model checking problem in
the style of \textcite{clarke_design_1982}:

\begin{displaycquote}[p. 2]{clarke_design_1982}
  ...mechanically determine if the system meets a specification expressed in
  propositional temporal logic.
\end{displaycquote}

In this section I will describe the techniques used to check a program against a
TESLA assertion. I describe an abstract structure derivable from LLVM IR that
represents a program, as well as a set of algorithms that check whether a
particular structure is a model for a specification automata. Finally, I discuss
the limitations and potential improvements that could be made to this approach.

\subsection{Data Flow Inference}

Because TESLA allows for data flow properties to be asserted, a mechanism to do
so statically is required for the model checker to be fully useful. The two
forms of data flow assertion allowed by TESLA are constraints on the arguments
passed to a function, and on the value returned by a function call. The dynamic
implementation of TESLA includes code for mapping from an abstract
representation of function arguments onto LLVM values (as this is required to
insert instrumentation code). This code is reused in the model checker, and so
the model checker only has to be able to check function return values.

Stated more formally, the property we are interested in checking is
\textquote{on a particular execution path, can we infer that a function call
returned a fixed value?}. In this section, I describe an algorithm for
performing this inference by making use of an SMT\footnote{Satisfiability Modulo
Theories} encoding of LLVM IR.

\subsubsection{Encoding LLVM IR as SMT Formulae}

In \autoref{sec:smt} I gave an overview of SMT methods, their history and
relevant terminology. Building on this background, in this section I describe
how an LLVM function can be encoded as an SMT problem that when solved gives a
solution to the function return value inference problem described above.

Because LLVM IR is expressed in SSA\footnote{Static Single Assignment} form, it
admits a relatively simple encoding as SMT formulae. For example, the LLVM
instruction \mintinline{llvm}{%3 = add i32 %1, %2} can be seen as a formulae
stating that $ \%_3 = \%_1 + \%_2 $, whatever interpretation is given to the
values $ \%_1 $ and $ \%_2 $. This encoding relies on a particular background
theory (for example, the theory of finite bit vectors---one leading
implementation of which is Boolector \cite{brummayer_boolector:_2009}) to supply
the semantics of $ + $ and other operations. All of the LLVM binary and
comparison operators can be encoded into interpreted SMT functions using this
method.

While it is possible to provide a defined interpretation of some LLVM values, it
is more interesting to consider the ones where we cannot. We have no way of
supplying an interpretation for a function call or a load from memory, for
example. Instructions in this class are encoded as uninterpreted constants in
the same background theory---they will be assigned values in a satisfying model.

A particular execution path through a function is given by a sequence of basic
blocks from entry to termination (through ordinary return or otherwise). From
this execution path we are able to determine the truth values of each branch
condition---these branch conditions uniquely determine control flow and vice
versa. Each of these truth values can then be added to the SMT interpretation of
the IR as an assertion.

The result of applying this translation to a particular execution path is an SMT
instance such that when a model is found, it may give a valuation to the return
value of function calls. It is possible that no valuation for a function call is
found (for example, if no branches depend on its return value), or that several
models are possible. Because TESLA assertions specify a fixed value for a
function return value, we must check that exactly one model is possible---this
can be done by solving an augmented problem that includes the negation of the
original solution as assertions. For example, if \texttt{\%3 = 12} is identified
as a solution, adding \texttt{\%3 != 12} as an assertion causes the problem to
become unsatisifiable if there was only one possible model.

Finally, after translating a function execution and finding a unique model, we
are left with a mapping from call sites to fixed return values on the execution.
\autoref{fig:llvm-smt} contains a fragment of LLVM IR taken from the test suite
of mutex programs, and \autoref{fig:smt-example} shows the translation of this
IR into an SMT program (given using SMT-LIB2 standardised syntax
\cite{BarST-SMT-10}).

% TODO get lexer and populate these listings with actual example code

\begin{listing}
  \begin{minted}{llvm}
  \end{minted}
  \caption{LLVM IR to be translated into an SMT problem}
  \label{fig:llvm-smt}
\end{listing}

\begin{listing}
  \begin{minted}{haskell}
  \end{minted}
  \caption{SMT translation of LLVM IR}
  \label{fig:smt-example}
\end{listing}

\subsubsection{Implementation}

Implementing the algorithm described above requires several transformations to
be made to an LLVM function before it can be transformed to its SMT
representation. First, because execution is modelled as a sequence of basic
blocks, the function must be completely inlined. This is easily achieved using
existing LLVM library code (with the caveat that infinite recursion can only be
inlined up to a finite depth).

Once the function has been inlined, all of its call sites are removed---this
means we lose information about arguments passed and values returned. To remedy
this problem, calls to stub functions are added before and after each call site
to be inlined. Each stub function receives the same arguments as the call being
made, and the return value of the call is replaced by the return value of the
``after'' stub. The stub functions are not inlined, preserving call graph
information in the inlined function.

Execution sequences are generated from the inlined function by walking its
control flow graph to a specified finite depth---this finiteness condition is
addressed further in \autoref{sec:evg}. Repeated basic blocks from loops in the
graph are handled by simply duplicating the blocks.

From these execution sequences, the Z3 SMT solver \cite{de_moura_z3:_2008} is
used to construct and solve the SMT problem. Z3 was chosen as a
production-quality SMT implementation with a well-documented C++ API.

\subsection{Program Event Graphs} \label{sec:evg}

From its position in the TESLA toolchain, the inputs available to the model
checking tool are:
\begin{itemize}
  \item The manifest file containing all assertions and usages thereof from the
    program.
  \item A single LLVM bitcode file (obtained using
    \texttt{llvm-link}\footnote{\url{http://releases.llvm.org/3.4/docs/CommandGuide/llvm-link.html}})
    that has not yet been instrumented or optimised.
\end{itemize}
In order to define a model checking algorithm, we must first define a
\emph{structure} that will be checked against the specification. Because our
specification automata are defined in terms of program events (function calls,
returns, assertion sites and field assignments), it is natural that the
structure extracted from the LLVM IR represents these events in some form.

\autoref{lst:ir-example} shows an example LLVM IR function that uses a lock from
\autoref{sec:locks} correctly. Some of the structure we are interested in is
already apparent---calls to \mintinline{c}{lock_acquire} and
\mintinline{c}{lock_release} are made in the function along with the appropriate
checks on the return values. However, using the LLVM IR as the model-checking
structure directly is not convenient (it contains a great deal of redundant
information and indirection through function calls makes analysis more
difficult).

\begin{listing}
  \begin{minted}{llvm}
define void @do_work() #0 {
  br label %1

  ; <label>:1 ; preds = %4, %0
  %2 = call zeroext i1 @lock_acquire(%struct.lock_st* @lock)
  %3 = xor i1 %2, true
  br i1 %3, label %4, label %5

  ; <label>:4 ; preds = %1
  br label %1

  ; <label>:5 ; preds = %1
  call void @lock_release(%struct.lock_st* @lock)
  ret void
}
  \end{minted}
  \caption{LLVM IR with correct lock usage}
  \label{lst:ir-example}
\end{listing}

The solution chosen is to convert the IR module into an \emph{event graph} that
contains only the program events we are interested in and that makes control
flow between these events more explicit.

To construct such an event graph, I used a variation of function
inlining. Every function in the module can be converted to a directed graph
with instructions as vertices and control flow determining the
edges.\footnote{This step is purely a conversion between representations; a
function is a graph of basic blocks that already encodes the same information
about control flow.}

Next, every instruction that is not a function call is removed from the graph
(preserving transitive control flow edges).\footnote{Assertion site events are
preserved by this step because of their representation as calls to a marker
function.} The function graphs are then \textquote{bookended} with an entry and
exit vertex such that there is a unique node with no predecessors, and similarly
a unique node with no successors. The event graph extracted from the IR in
\autoref{lst:ir-example} is shown in \autoref{fig:event-graph-single}.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}
    \node[instr] (entry) {Entry};
    \node[instr,below=of entry] (1) {\mintinline{llvm}{call @lock_acquire(...)}};
    \node[instr,below=of 1] (5) {\mintinline{llvm}{call @lock_release(...)}};
    \node[instr,below=of 5] (exit) {Exit};

    \draw[-latex] (entry) -- (1);
    \path[-latex] (1.4) edge  [out=30,in=330,distance=1cm] node[anchor=west] {}
    (1.356);
    \draw[-latex] (1) to (5);
    \draw[-latex] (5) to (exit);
  \end{tikzpicture}
  \caption{Program event graph for a single function}
  \label{fig:event-graph-single}
\end{figure}

Finally, every call instruction is replaced by a copy of the event graph for the
call's target (or by an appropriate assertion site event, if the function call
is to the assertion marker function). Note that any loops in the call graph
arising from recursive calls will never be fully inlined---this is a limitation
of the approach, and is not easily resolved. 

A partial solution in the context of the TESLA model checker is to inline
recursive calls up to a specified call depth, and no further. There is no
simple, general solution to this problem, supported by similar instances in the
literature---\textcite{henry_pagai:_2012} apply inlining to avoid the problem of
interprocedural analysis, but do not address the problem of recursive calls,
while \textcite{wang_function_2009} disallow recursion entirely in programs they
analyse.

From this inlining step we obtain a whole-program graph of program events, with
edges representing control flow between these events.

\subsection{Model Checking Algorithm} \label{sec:mc}

Now that the structure and specification for the TESLA model checking problem
are defined, the next step is to implement an algorithm by which satisfaction
can be checked mechanically.

\subsubsection{Single-Edge Acceptance}

First, we define a single-edge acceptance criterion that defines when a program
event is accepted by an edge in the specification automaton (this is required
because edges in the specification automaton have attached metadata that program
events do not). This acceptance criterion is defined to be equality over all
metadata fields that program events carry. In more detail, these are:
\begin{description}
  \item[Function Events] The associated function, direction and parameters
  \item[Assertion Site Events] The assertion site location
\end{description}
Note that this criterion does not discriminate on function return values---this
is a deliberate choice, and the resulting imprecision is addressed in
\autoref{sec:rvc}. Another consequence of not discriminating on function return
values is that previously deterministic specification automata are no longer
deterministic---if there are multiple transitions for the same function and
parameter combination, each will accept the same events regardless of the
constraints placed on their return values.

\subsubsection{Graph Acceptance}

Given a criterion for single-edge acceptance of a program event, the next step
is to define when a program event graph is accepted by a specification
automaton.

An initial (and partially inadequate) definition is to say that a graph is
accepted by an automaton if and only if every path of events through the graph
from entry to exit reaches an accepting state in the specification automaton.
This definition is reminiscent of the definition of satisfaction for LTL, where
a formula is satisfied over a structure if and only if it is on all possible
linear paths in that structure. However, this fails to capture two important
features of TESLA assertions:
\begin{description}
  \item[Boundedness] For a given specification automaton, we are not interested
    in events that fall outside of its bounding interval.
  \item[Non-termination] Programs with TESLA assertions may never
    terminate. This is perfectly valid---as long as the program never
    performs an event not permitted by an automaton, it will not fail
    its TESLA assertions.
\end{description}

To capture the boundedness criterion, we refine our original definition to
quantify over all paths over the bounding interval (for example, all paths from
a call event to a matching return event).

Non-termination is added to this definition by including all paths that begin at
the start of the bounding interval and enter an infinite loop. These
paths may not include an accepting state, and so a path with an infinite
loop satisfies the specification as long as the path does not contain an
event forbidden by the automaton.

\subsubsection{Implementation}

I now describe an implementation of an algorithm that performs the graph
acceptance check described previously. A na\"ive translation of the
specification given above (i.e.\ quantifying over \emph{all} paths
through the bounding interval) is clearly not viable---even the
small single-function graph in \autoref{fig:event-graph-single} has an
infinite\footnote{To be more precise, the number of paths is only
\emph{countably} infinite, by a simple argument on the number of times
the looping state is visited.} number of paths from entry to exit!

A pragmatic solution to this problem is to employ \emph{bounded} model
checking, where only paths through the graph of length $ \leq k $ (where
$k$ is an arbitrary constant) are considered. While this method is
perhaps not appealing from a theoretical standpoint, it is well studied
in the context of systems software (see
\autoref{sec:bounded-model-checking} for a full review of related work).

To implement the definition given previously, the notion of
\textquote{infinite loop} must be sensibly defined in the context of
bounded paths. To do this, we generate every path through the event
graph of length $\leq k$, classifying each as either terminating,
looping or incomplete:
\begin{description}
  \item[Terminating] paths are those that reach the end of the bounding
    interval in $k$ or fewer steps.
  \item[Looping] paths have a suffix made up of more than one
    repetition of a shorter suffix (this characterises infinite loops
    because if the shorter suffix can be repeated more than once, it can
    be repeated any number of times).
  \item[Incomplete] paths are not terminating or looping.
\end{description}

Then to check whether the specification automaton is a model for the
event graph, each terminating and looping path is checked against the
automaton using the acceptance criteria given above. If every path is
accepted by the automaton, then the assertion always holds---the
instrumentation for the assertion can therefore be safely removed from
the program.

\subsection{Limitations and Improvements} \label{sec:model-limits}

\subsubsection{Performance}

Generally speaking, running the model checker is computationally
expensive. However, it is designed to check shorter event paths first,
such that a counterexample can be generated as soon as possible if one
exists (the other benefit of this approach is that shorter
counterexamples are easier for the user to understand).

In practical terms, this means that assertions that have a
counterexample can be checked a great deal faster than those that do
not---if there is no counterexample, then every path shorter than the
bounding length must be checked. For example, checking any incorrect
test case from \autoref{sec:hand-coded} with a bound of 5000
instructions takes approximately 15 seconds, while the successful test
cases take around 90 seconds.

\subsubsection{Field Assignments}

As noted previously, the model checker cannot check any assertion that
contains a structure field assignment. This limitation arises because
field assignments are inherently \emph{value-dependent}---locating the
IR instruction that assigns to a structure field is easily done, but
computing the value assigned is not easy (in the general case).

A TESLA-specific solution to this issue would be to devise a way of
splitting assertions such that statically provable components are proved
where possible, leaving behind components of the assertion that must be
instrumented dynamically. This approach would require major changes to
some TESLA internals, and was found not to be feasible within the scope
of this project (allowing for the work already done).
