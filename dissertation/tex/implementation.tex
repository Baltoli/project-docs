\section{Modelling Locks with TESLA} \label{sec:locks}

\begin{displaycquote}[p. 1]{anderson_tesla:_2014}
TESLA exposes run-time behaviour using program instrumentation, illuminating
coverage of complex state machines and detecting violations of specifications.
\end{displaycquote}

\textcite{anderson_tesla:_2014} draw attention to the suitability of TELSA for
modelling and verifying \emph{state machines} within a program. In this section,
I describe a set of TESLA assertions that ensure the safe usage of a simple
mutual-exclusion lock---these assertions will act as a running example
throughout the rest of the chapter to provide context to the analyses developed
and demonstrate an application of static analysis to TESLA assertions.

Mutual exclusion locks were chosen as the structure to model in this section
because while the number of states and associated operations is small, the state
machine has properties that are non-trivial to analyse statically.

\subsection{Lock Structure}

The lock structure to be modelled in this section is a simple structure wrapper
around a C11 atomic boolean value, together with a set of functions that operate
on these structures.

\begin{listing}[ht]
  \begin{minted}{c}
  #include <stdatomic.h>
  #include <stdbool.h>

  typedef struct lock_st {
    _Atomic(bool) locked
  } lock_t;

  void lock_init(lock_t *lock) {
    atomic_init(&(lock->locked), false);
  }

  bool lock_acquire(lock_t *lock) {
    bool f = false;
    return atomic_compare_exchange_strong(
            &(lock->locked), &f, true);
  }

  void lock_release(lock_t *lock) {
    lock->locked = false;
  }

  void lock_free(lock_t *lock) {
  }
  \end{minted}
  \caption{Implementation of a mutual exclusion lock with C11 atomics}
  \label{lst:mutex}
\end{listing}

The four operations provided by this interface are initialisation,
deinitialisation (for the given lock implementation this is a no-op, but it may
not be for more complex variants), non-blocking acquisition and release. Lock
acquisition is implemented using atomic compare-and-swap, returning
\mintinline{c}{false} if the lock is being held by another user or \mintinline{c}{true}
if the acquisition was successful.

\subsection{Lock Usage}

Using the non-blocking acquisition function described previously, it is possible
to implement a blocking spin-lock in terms of a lock structure:

\begin{minted}{c}
while(!lock_acquire(lock)) {}
\end{minted}

The usage of the lock structure that I have developed assertions to verify is in
fact this spin-lock (i.e.\ where users of the lock repeatedly attempt to acquire
it, execute their critical section, then release it).

Correct usage of the lock in this way can be summarised informally by a set of
invariants:
\begin{itemize}
  \item Consumers can fail to acquire the lock any number of times
  \item Once the lock is acquired, no more attempts to acquire can be made
  \item The lock is released exactly once after being successfully acquired
\end{itemize}

\subsection{TESLA Assertions}

The properties described previously are well-suited to being expressed as TESLA
assertions---they express temporal relationships between program events (calls
to the functions \mintinline{c}{lock_acquire} and \mintinline{c}{lock_release}).

Expressed as TESLA assertions using the explicit automaton style, the properties
are:
\begin{listing}[ht]
  \begin{minted}{c}
  automaton(acq_rel, lock_t *lock) {
    acquire(lock);
    release(lock);
    tesla_done;
  }

  automaton(acquire, lock_t *lock) {
    optional(ATLEAST(1, lock_acquire(lock) == false));
    lock_acquire(lock) == true;
    tesla_done;
  }

  automaton(release, lock_t *lock) {
    returnfrom(lock_release(lock));
    tesla_done;
  }
  \end{minted}
  \caption{Mutex lock properties expressed using TESLA}
  \label{lst:mutex-tesla}
\end{listing}

Writing \mintinline{c}{optional(ATLEAST(1, ...))} is required to work around a
limitation in the TESLA instrumenter code that prevents
\mintinline{c}{ATLEAST(0, ...)} from compiling. The semantics in both cases are
the same, so this is not a major issue.

\subsection{Performance Overhead}

The lock assertions can be used to provide an example of the performance
overhead imposed by instrumenting code with TESLA (and consequently, the
potential benefits of removing safe assertions at compile time).

\subsubsection{Experimental Setup}

The benchmark code used in this demonstration creates a number of
threads, each of which attempts to sort a randomly chosen interval of a
large shared array. Threads access the array under mutual exclusion,
protected by a lock as described in \autoref{lst:mutex}---this creates
contention on the lock, dependent on the number of executing threads.

A single TESLA assertion is added to the benchmark to assert the correct
usage of the mutual exclusion lock on the shared array. Two versions of
the program are generated---one with the TESLA instrumentation left in
place, and another with the instrumentation elided using the model
checker described in \autoref{sec:checking}. Both versions are compiled
using release build settings.

Both programs were run with the same parameters (threads sort an
interval of size \num{15000} from a larger array of size \num{500000},
and the number of threads was varied from 8 to 40), with results
averaged over 5 runs of the program.

The benchmarks were run on my development machine (Intel Xeon E5-1620
\SI{3.6}{\GHz}, 8 cores, 64GB of RAM) running FreeBSD 11.

\subsubsection{Results}

Before the two benchmark programs are even run, one benefit of removing
instrumentation is clear---the binary with its assertions removed is 25\%
smaller than the instrumented binary (\num{19.1} KiB vs. \num{25.3}
KiB).

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      title={Effect of contention on benchmark runtime},
      width=0.85\textwidth,
      xlabel={No. of Threads},
      ylabel={Runtime (s)},
      xmin=5,xmax=43,
      ymin=0,ymax=70,
      xtick={8,16,24,32,40},
      legend pos=north west,
      ymajorgrids=true,
      grid style=dashed,
      cycle list/Dark2,
    ]
      \addplot+[mark=x]
      table [x =x, y =sy, y error =se]{data/locks_bench.dat};

      \addplot+[mark=x]
      table [x =x, y =iy, y error =ie]{data/locks_bench.dat};
      \legend{Uninstrumented,Instrumented}
    \end{axis}
  \end{tikzpicture}
  \caption{Runtime of instrumented and uninstrumented benchmarks at
  varying levels of lock contention}
  \label{fig:locks-bench}
\end{figure}

The results from running the two benchmark programs as described above
are shown in \autoref{fig:locks-bench}. At low levels of contention
there is little difference between the programs---this is because the
TESLA instrumentation code is only executed during lock acquisition and
releasing. However, at higher levels of contention more time is spent in
the TESLA instrumentation code, and the instrumented version shows a
slowdown relative to the uninstrumented version.

From these results the benefits of performing static analysis on TESLA
assertions can be seen---if the assertions lie on a frequently executed code
path, then a runtime performance improvement is likely. A decrease in
binary size is also likely, even if the assertions are executed only
infrequently.

\section{Hand-Coded Static Analysis} \label{sec:hand-coded}

The first approach taken to static analysis of TESLA assertions was to develop
\textquote{special-cased} assertions that attempt to prove properties only for a
single assertion (in this case, \mintinline{c}{acq_rel}).

Because TESLA assertions describe safety properties of programs, the approach
taken is to examine each individual usage of the assertion in question for
possible \textquote{bad things} that could cause the assertion to fail. If none
are found, then the assertion will always succeed at compile time and the
corresponding instrumentation code can be removed safely.

To implement this analysis, a set of cases in which the invariants described
previously could possibly fail was compiled. Some of the simpler possible safety
violations for \mintinline{c}{acq_rel} are:
\begin{itemize}
  \item Either of the lock interface functions have their address taken
  \item One or both of the functions are not called at all
  \item There is no branch on the result of a call to
  \mintinline{c}{lock_acquire}
\end{itemize}

In order to check that these safety properties are not violated, I implemented a
collection of LLVM \cite{lattner_llvm:_2002} analysis passes that each check a
single safety property. As well as these passes, I implemented a small test
suite of programs that use the lock interface (adapted somewhat to allow for
consistent testing).

\begin{table}[ht]
  \centering
  \begin{tabularx}{\textwidth}{Z | Z}
    \toprule
    \textbf{Test Name} & \textbf{Correct?} \\
    \midrule
    address & No \\
    basic & Yes \\
    basic\_indirect & Yes \\
    more\_usage & No \\
    mult\_acq & No \\
    mult\_rel & No \\
    no\_acq\_rel & No \\
    no\_acq & No \\
    no\_rel & No \\
    one\_acq & No \\
    other & No \\
    rel\_before & No \\
    rel\_before\_indirect & No \\
    \bottomrule
  \end{tabularx}
  \caption{Summary of \mintinline{c}{acq_rel} test programs}
\end{table}

The aim of these test cases is to provide a minimal set of test cases
against which the correctness of the analyses can be checked. Each
potential safety violation identified occurs at least once in the test
suite.

\subsection{Results}

While there are some advantages to writing assertion safety analyses in
this way, it is far from an ideal approach to the problem. The key
problems are:
\begin{description}
  \item[Development Time] Developing the LLVM analysis passes takes a
    long time (even allowing for the time spent developing
    \textquote{infrastructure} code).
  \item[Inflexibility] Even a small change to the assertions being
    analysed can mean a large change to the analysis being applied.
  \item[Duplicate Logic] The assumptions made in the assertions must be
    duplicated and spread across multiple passes.
\end{description}

In order to address these issues, we require a system of analysis that can be
built once \textquote{up front}, can be applied to any TESLA assertions
regardless of the properties that they encode and that does not rely on any
specific knowledge of the assertion being checked.

\section{Formalising TESLA Assertions} \label{sec:formal}

In order to generalise the hand-coded analysis style to arbitrary assertions
(rather than specific instances where the relevant properties and failure
conditions are known ahead of time), it is necessary to define a more abstract
model of the semantics of TESLA assertions and the programs to which they are
applied.

The hand-coded analysis relied on developer-supplied knowledge of the failure
conditions for the assertion being checked, which could then be translated into
analysis passes to be run on the program's intermediate representation.

TESLA assertions \textcquote[p. 3]{anderson_tesla:_2014}{have a natural
expression as finite-state automata that can be mechanically woven into a
program}. However, the exact manner in which these automata are constructed is
only touched upon briefly in the paper. In this section, I provide a formal
translation of TESLA automata into corresponding finite state automata.

The automata constructions given in this section are nondeterministic, with
$\varepsilon$-transitions in some places. It is worth noting the well-known
result that a non-deterministic automaton with $n$ states can always be
converted to an equivalent deterministic automaton with up to $2^n$ states
\cite{rabin_finite_1959}. However, in practice the automata constructed using
the methods described in this section do not experience this exponential
increase in size.

\subsection{Program Events}

As described in \autoref{sec:assertions}, TESLA allows temporal relationships
between function calls or returns, assertion sites and structure field
assignments to be expressed. These events are the \textquote{building blocks}
from which an automaton is constructed.

These events have no recursive structure---they only define a program event to
be matched. As a result, the automata they define are very simple.
\autoref{fig:event-auto} shows the constructed automaton for an arbitrary program event
$e$---it has a single transition from the initial state to the accepting state,
labelled by the event $e$.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (start) [] {$q_0$};
    \node[state,accepting] (end) [right=of start] {$q_1$};
    %\node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \path[->] (start) edge node {$e$} (end);
  \end{tikzpicture}
  \caption{Program event automaton}
  \label{fig:event-auto}
\end{figure}

The structure of this automaton is the same no matter what event $e$ it was
constructed for, and it implicitly captures all the properties $e$ may have
(e.g.\ function name, return value or assertion site location). In
\autoref{sec:checking} I give a full description of how these properties are
used to check properties of a program.

\subsection{Composition}

There are two ways in which TESLA automata may be composed---sequential ordering
and disjunction (corresponding to the concrete syntax \mintinline{c}{TSEQUENCE}
and \mintinline{c}{||} respectively). The TESLA source code does in fact make
reference to a conjunction operation on automata, but it is not fully
implemented.\footnote{The protocol buffer format for assertions makes provision
for the extra boolean operation type, but using it in an assertion is
unsupported.} Assertions of these types have recursive structure (i.e. they
contain other automata), and so their constructed automata are defined as
compositions of other automata.

By convention, sub-automata are shown inside dashed boxes. Accepting states
inside these boxes are the accepting states of the sub-automaton, and dotted
lines indicate transitions that are internal to the subautomaton.

\subsubsection{Sequential Ordering}

The simplest temporal relationship TESLA enforces is sequential ordering
(\textquote{event $a$ happens, then event $b$ happens...}). Sequence assertions
may be repeated, and have attributes specifying the minimum and maximum number
of repetitions that are permitted (with the maximum number being potentially
infinite). Sequences may contain any number of sub-assertions.

The cases where exactly one repetition or an infinite number of repetitions is
allowed are easy to define in terms of the sub-automata. The examples given in
\autoref{fig:seq-one-auto} and \autoref{fig:seq-inf-auto} have two subautomata,
but the construction generalises simply to any number.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below=of start] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [right=of end2] (realend) {$q1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (end2) edge node {$\varepsilon$} (realend);
    \draw[->,out=270,in=90] (end.south) to node[above]{$\varepsilon$} (start2.north);
  \end{tikzpicture}
  \caption{Single repetition sequence automaton}
  \label{fig:seq-one-auto}
\end{figure}

From a single repetition, an automata that can recognise an infinite number is
obtained by adding an $\varepsilon$-transition back from the accepting state to
the initial state.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below=of start] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [right=of end2] (realend) {$q_1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (end2) edge node {$\varepsilon$} (realend);
    \draw[->,out=270,in=90] (end.south) to node[above]{$\varepsilon$} (start2.north);

    \draw[->,looseness=1.2,out=90,in=45] (realend.north) to node[above]{$\varepsilon$} (realstart.north east);
  \end{tikzpicture}
  \caption{Infinite repetition sequence automaton}
  \label{fig:seq-inf-auto}
\end{figure}

If the sequence is not exactly-once or infinite, then a copy of the entire
sequence automaton (as in \autoref{fig:seq-one-auto}) must be constructed for
each repetition. The copies in the valid range (between the minimum and the
maximum number of repetitions) have an $\varepsilon$-transition from their
accepting state to the overall accepting state. As a consequence of this, the
size of the constructed automata is directly proportional to the maximum number
of repetitions (if the maximum is finite).

\subsubsection{Disjunction}

A disjunction automaton will accept if \emph{any} of its subautomata do (i.e.\
it implements logical or over its subautomata), and can therefore be constructed
as shown in \autoref{fig:disj-auto} (again, the diagram shows the case for two
subautomata, but the construction generalises to any number).

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [above right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below right=of realstart] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [above right=of end2] (realend) {$q1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (realstart) edge node[below left] {$\varepsilon$} (start2);
    \path[->] (end) edge node {$\varepsilon$} (realend);
    \path[->] (end2) edge node[below right] {$\varepsilon$} (realend);
  \end{tikzpicture}
  \caption{Disjunction automaton}
  \label{fig:disj-auto}
\end{figure}

\section{Model Checking TESLA} \label{sec:checking}

Previously (in \autoref{sec:formal}) I gave a translation from TESLA assertions
to nondeterministic finite automata with transitions labeled with program event
assertions. This automaton can be seen as a \emph{specification} for a program,
expressed in a form of temporal logic. To check whether a program is correct
with regard to this specification can now be seen as a model checking problem in
the style of \textcite{clarke_design_1982}:

\begin{displaycquote}[p. 2]{clarke_design_1982}
  ...mechanically determine if the system meets a specification expressed in
  propositional temporal logic.
\end{displaycquote}

In this section I will describe the techniques used to check a program against a
TESLA assertion. I describe an abstract structure derivable from LLVM IR that
represents a program, as well as a set of algorithms that check whether a
particular structure is a model for a specification automata. Finally, I discuss
the limitations and potential improvements that could be made to this approach.

\subsection{Program Event Graphs}

From its position in the TESLA toolchain, the inputs available to the model
checking tool are:
\begin{itemize}
  \item The manifest file containing all assertions and usages thereof from the
    program.
  \item A single LLVM bitcode file (obtained using
    \texttt{llvm-link}\footnote{\url{http://releases.llvm.org/3.4/docs/CommandGuide/llvm-link.html}})
    that has not yet been instrumented or optimised.
\end{itemize}
In order to define a model checking algorithm, we must first define a
\emph{structure} that will be checked against the specification. Because our
specification automata are defined in terms of program events (function calls,
returns, assertion sites and field assignments), it is natural that the
structure extracted from the LLVM IR represents these events in some form.

\autoref{lst:ir-example} shows an example LLVM IR function that uses a lock from
\autoref{sec:locks} correctly. Some of the structure we are interested in is
already apparent---calls to \mintinline{c}{lock_acquire} and
\mintinline{c}{lock_release} are made in the function along with the appropriate
checks on the return values. However, using the LLVM IR as the model-checking
structure directly is not convenient (it contains a great deal of redundant
information and indirection through function calls makes analysis more
difficult).

\begin{listing}
  \begin{minted}{llvm}
define void @do_work() #0 {
  br label %1

  ; <label>:1 ; preds = %4, %0
  %2 = call zeroext i1 @lock_acquire(%struct.lock_st* @lock)
  %3 = xor i1 %2, true
  br i1 %3, label %4, label %5

  ; <label>:4 ; preds = %1
  br label %1

  ; <label>:5 ; preds = %1
  call void @lock_release(%struct.lock_st* @lock)
  ret void
}
  \end{minted}
  \caption{LLVM IR with correct lock usage}
  \label{lst:ir-example}
\end{listing}

The solution chosen is to convert the IR module into an \emph{event graph} that
contains only the program events we are interested in and that makes control
flow between these events more explicit.

To construct such an event graph, I used a variation of function
inlining. Every function in the module can be converted to a directed graph
with instructions as vertices and control flow determining the
edges.\footnote{This step is purely a conversion between representations; a
function is a graph of basic blocks that already encodes the same information
about control flow.}

Next, every instruction that is not a function call is removed from the graph
(preserving transitive control flow edges).\footnote{Assertion site events are
preserved by this step because of their representation as calls to a marker
function.} The function graphs are then \textquote{bookended} with an entry and
exit vertex such that there is a unique node with no predecessors, and similarly
a unique node with no successors. The event graph extracted from the IR in
\autoref{lst:ir-example} is shown in \autoref{fig:event-graph-single}.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}
    \node[instr] (entry) {Entry};
    \node[instr,below=of entry] (1) {\mintinline{llvm}{call @lock_acquire(...)}};
    \node[instr,below=of 1] (5) {\mintinline{llvm}{call @lock_release(...)}};
    \node[instr,below=of 5] (exit) {Exit};

    \draw[-latex] (entry) -- (1);
    \path[-latex] (1.4) edge  [out=30,in=330,distance=1cm] node[anchor=west] {}
    (1.356);
    \draw[-latex] (1) to (5);
    \draw[-latex] (5) to (exit);
  \end{tikzpicture}
  \caption{Program event graph for a single function}
  \label{fig:event-graph-single}
\end{figure}

Finally, every call instruction is replaced by a copy of the event graph for the
call's target (or by an appropriate assertion site event, if the function call
is to the assertion marker function). Note that any loops in the call graph
arising from recursive calls will never be fully inlined---this is a limitation
of the approach, and is not easily resolved. 

A partial solution in the context of the TESLA model checker is to inline
recursive calls up to a specified call depth, and no further. There is no
simple, general solution to this problem, supported by similar instances in the
literature---\textcite{henry_pagai:_2012} apply inlining to avoid the problem of
interprocedural analysis, but do not address the problem of recursive calls,
while \textcite{wang_function_2009} disallow recursion entirely in programs they
analyse.

From this inlining step we obtain a whole-program graph of program events, with
edges representing control flow between these events.

\subsection{Model Checking Algorithm}

Now that the structure and specification for the TESLA model checking problem
are defined, the next step is to implement an algorithm by which satisfaction
can be checked mechanically.

\subsubsection{Single-Edge Acceptance}

First, we define a single-edge acceptance criterion that defines when a program
event is accepted by an edge in the specification automaton (this is required
because edges in the specification automaton have attached metadata that program
events do not). This acceptance criterion is defined to be equality over all
metadata fields that program events carry. In more detail, these are:
\begin{description}
  \item[Function Events] The associated function, direction and parameters
  \item[Assertion Site Events] The assertion site location
\end{description}
Note that this criterion does not discriminate on function return values---this
is a deliberate choice, and the resulting imprecision is addressed in
\autoref{sec:rvc}. Another consequence of not discriminating on function return
values is that previously deterministic specification automata are no longer
deterministic---if there are multiple transitions for the same function and
parameter combination, each will accept the same events regardless of the
constraints placed on their return values.

\subsubsection{Graph Acceptance}

Given a criterion for single-edge acceptance of a program event, the next step
is to define when a program event graph is accepted by a specification
automaton.

An initial (and partially inadequate) definition is to say that a graph is
accepted by an automaton if and only if every path of events through the graph
from entry to exit reaches an accepting state in the specification automaton.
This definition is reminiscent of the definition of satisfaction for LTL, where
a formula is satisfied over a structure if and only if it is on all possible
linear paths in that structure. However, this fails to capture two important
features of TESLA assertions:
\begin{description}
  \item[Boundedness] For a given specification automaton, we are not interested
    in events that fall outside of its bounding interval.
  \item[Non-termination] Programs with TESLA assertions may never
    terminate. This is perfectly valid---as long as the program never
    performs an event not permitted by an automaton, it will not fail
    its TESLA assertions.
\end{description}

To capture the boundedness criterion, we refine our original definition to
quantify over all paths over the bounding interval (for example, all paths from
a call event to a matching return event).

Non-termination is added to this definition by including all paths that begin at
the start of the bounding interval and enter an infinite loop. These
paths may not include an accepting state, and so a path with an infinite
loop satisfies the specification as long as the path does not contain an
event forbidden by the automaton.

\subsubsection{Implementation}

I now describe an implementation of an algorithm that performs the graph
acceptance check described previously. A na\"ive translation of the
specification given above (i.e.\ quantifying over \emph{all} paths
through the bounding interval) is clearly not viable---even the
small single-function graph in \autoref{fig:event-graph-single} has an
infinite\footnote{To be more precise, the number of paths is only
\emph{countably} infinite, by a simple argument on the number of times
the looping state is visited.} number of paths from entry to exit!

A pragmatic solution to this problem is to employ \emph{bounded} model
checking, where only paths through the graph of length $ \leq k $ (where
$k$ is an arbitrary constant) are considered. While this method is
perhaps not appealing from a theoretical standpoint, it is well studied
in the context of systems software (see
\autoref{sec:bounded-model-checking} for a full review of related work).

To implement the definition given previously, the notion of
\textquote{infinite loop} must be sensibly defined in the context of
bounded paths. To do this, we generate every path through the event
graph of length $\leq k$, classifying each as either terminating,
looping or incomplete:
\begin{description}
  \item[Terminating] paths are those that reach the end of the bounding
    interval in $k$ or fewer steps.
  \item[Looping] paths have a suffix made up of more than one
    repetition of a shorter suffix (this characterises infinite loops
    because if the shorter suffix can be repeated more than once, it can
    be repeated any number of times).
  \item[Incomplete] paths are not terminating or looping.
\end{description}

Then to check whether the specification automaton is a model for the
event graph, each terminating and looping path is checked against the
automaton using the acceptance criteria given above. If every path is
accepted by the automaton, then the assertion always holds---the
instrumentation for the assertion can therefore be safely removed from
the program.

\subsection{Return Value Constraints} \label{sec:rvc}

The bounded model checking algorithm described in the previous section
is in fact unsound with respect to one particular class of
assertions---if the assertion has constraints on the return value of
some function calls, then the model checker may report that an unsafe
program is actually safe. This is clearly a more serious issue than the
converse---safe programs being reported as unsafe is simply
\emph{imprecision} in the algorithm, and affects performance rather than
correctness.

In this section I describe an algorithm that can be applied to resolve
this unsoundness, along with a discussion on how the techniques used
could be extended to permit a less conservative analysis than is
implemented here.

\subsubsection{A Failing Example}

To motivate the rest of this section, I describe a program that suffers
from the unsoundess characterised above. The program is taken from the
test suite implemented in \autoref{sec:hand-coded}, and the relevant
parts of its source code are given in \autoref{lst:mult-acq}.

\begin{listing}[ht]
  \begin{minted}{c}
lock_t lock;

void do_work() {
  while(!lock_acquire(&lock)) {}
  while(!lock_acquire(&lock)) {}
  lock_release(&lock);
}

int main(void) {
  TESLA_WITHIN(main, eventually(
    acq_rel(&lock)
  ));

  do_work();
  return 0;
}
  \end{minted}
  \caption{An unsafe program incorrectly reported as safe}
  \label{lst:mult-acq}
\end{listing}

It is easy to intuit why the program in \autoref{lst:mult-acq} is
incorrect---when the second \mintinline{c}{while} loop is reached, the
lock must have been acquired, and so the second loop is always invalid
behaviour. More precisely, we can examine the transition sequence that
must be taken through the specification automaton for this program to be
accepted. A general representation of the transition sequence is given
in \autoref{fig:impossible}, with the two call sites for
\mintinline{c}{lock_acquire} disambiguated as \mintinline{llvm}{call (1)
...} and \mintinline{llvm}{call (2) ...} respectively.\footnote{These
call sites are separate objects in the LLVM in-memory representation,
and are disambiguated in this way purely for reading convenience.}
Dashed edges between events abbreviate potential repetition of the event
from which the edge originates.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}
    \node[instr] (assert) {\texttt{assertion site [line 10]}};
    \node[instr,below=of assert] (1) {\mintinline{llvm}{call (1) @lock_acquire(...) == false}};
    \node[instr,below=of 1] (2) {\mintinline{llvm}{call (1) @lock_acquire(...) == false}};
    \node[instr,below=of 2] (3) {\mintinline{llvm}{call (2) @lock_acquire(...) == false}};
    \node[instr,below=of 3] (4) {\mintinline{llvm}{call (2) @lock_acquire(...) == true}};

    \draw[-latex] (assert) -- (1);
    \draw[-latex,dashed] (1) -- (2);
    \draw[-latex] (2) -- (3);
    \draw[-latex,dashed] (3) -- (4);
  \end{tikzpicture}
  \caption{Sequence of program events in an unsafe program}
  \label{fig:impossible}
\end{figure}

The key problem with the transition sequence in \autoref{fig:impossible}
is that the first call at the second call site \emph{must} have been
preceded with a call at the first call site that returned
\mintinline{c}{false}. However, we have already noted (at least
informally) that this cannot happen---in the remainder of this section I
present an analysis that formalises this result.

\subsubsection{Path-sensitive Value Inference}

I now describe a classical data-flow analysis in the style introduced by
\textcite{kildall_unified_1973} (that is, one where the analysis
computes a function at each node of the control flow graph, iterating
until a convergent solution is reached).

The function we compute at each control flow node is the strongest
possible inference that can be made about the value taken by variables
in the IR before reaching the node.

\begin{listing}[ht]
  \begin{minted}{llvm}
define void @branch(i1 zeroext) #0 {
  br i1 %0, label %6, label %7

; <label>:6: ; preds = %1
  ; ... code ...
  br label %8

; <label>:7: ; preds = %1
  ; ... other code ...
  br label %8

; <label>:8: ; preds = %7, %6
  ret void
}
  \end{minted}
  \caption{LLVM IR example demonstrating control flow value inference}
  \label{lst:control-flow}
\end{listing}

\autoref{lst:control-flow} contains a simplified function written in
LLVM IR that can be used as an example of this analysis. There are two
possible execution paths through this function---one where block
\mintinline{llvm}{%6} is visited, and one where \mintinline{llvm}{%7} is
visited. If control reaches \mintinline{llvm}{%6}, then it is easy to
see that the value of \mintinline{llvm}{%0} must have been
\mintinline{llvm}{true} (and conversely for \mintinline{llvm}{%7}).
The aim of our analysis is to infer these constraints generically for
any function, even in the presence of more complex control flow
structures.

\subsubsection{Algorithm}

Our aim is to compute the strongest possible inference on IR variables
(an inference $A$ is stronger than an inference $B$ if $A \implies B
\land B \notimplies A$).

We first consider the \textquote{single step} version of the analysis.
Control flow may enter a basic block through any of its predecessors.
Each predecessor block has a strongest inference associated with it, as
well as a branch leading to the block in consideration. Therefore for
control flow to move from the predecessor to the current block, the
predecessor's strongest inference must hold, together with the
associated branch condition. Stated more formally, the strongest
inference at a basic block $n$ is defined as:
\[
  \mathrm{inf}(n) = \bigvee_{p \in \mathrm{preds}(n)}
    \mathrm{inf}(p) \land \mathrm{branch}(p,n)
\]

Initially, the inference at the entry block is $true$, and at every
other block it is $false$. This is because there is no possible
inference to be made from control flow reaching the entry block, and
every other block is assumed to be unreachable until the iteration
reaches them (an unreachable block has the strongest possible
inference---if control reaches such a block, then we can infer anything
about the previous execution state).

The algorithm to run the analysis on a single function is given as
pseudocode in \autoref{lst:infs-pseudo}.

\begin{listing}[ht]
  \begin{minted}[escapeinside=||]{s}
infs = [ false, ... ]
infs[entry] = true
while infs changes:
  for every basic block i:
    infs[i] = |$\bigvee_{\mathtt{p} \in \mathtt{preds(i)}}$| infs[p] |$\land$| branch(p,i)
  \end{minted}
  \caption{Strongest inference algorithm as pseudocode}
  \label{lst:infs-pseudo}
\end{listing}

\subsubsection{Application to the Model Checker}

The problem to be addressed by this data flow algorithm is that return
value constraints in assertions are ignored by the model checker.
However, what we have computed so far (inferences on the boolean values
taken by branch conditions) is not yet a solution. The final step is to
determine whether we can determine a relevant function return value
based on these inferences.

\begin{listing}[ht]
  \begin{minted}{llvm}
; ... preceding code ...
%2 = call i1 @lock_acquire(%struct.lock_st* @lock)
%3 = xor i1 %2, true
br i1 %3, label %4, label %5
  \end{minted}
  \caption{Branch value computed from function return value}
  \label{lst:branch-compute}
\end{listing}

The LLVM IR extract in \autoref{lst:branch-compute} is taken from one of
the programs in the test suite implemented in \autoref{sec:hand-coded}.
It shows an example of how a branch value can be computed from a
function return value of interest. Using the data flow algorithm on the
function this extract is taken from yields inferences on the value
\mintinline{llvm}{%3}. Given these inferences, we can then trace the
execution back through the basic block by hand to see that the branch
value is determined fully by the return value of \mintinline{llvm}{call
i1 @lock_acquire(...)}.

To integrate the data flow analysis into the model checker, I added a
basic implementation of this backwards tracing from the basic block
inferences. As implemented, only simple boolean operations are followed
(e.g.\ the \mintinline{llvm}{xor} instruction in
\autoref{lst:branch-compute}). In \autoref{sec:model-limits}, I discuss
how this approach could be extended to provide a less conservative
analysis.

Finally, the unsoundness described at the beginning of this section can
be addressed. When a path through the event graph is checked against a
specification automaton successfully, the transitions taken are
recorded. From these, a sequence of function return constraints is
extracted. If the path through the event graph passes through basic
blocks with exactly that sequence of observable inferences, then the
analysis is safe. If return values cannot be inferred, or the path does
not observe the exact sequence of inferences, then the analysis is
unsafe.

\subsection{Results}

When extended with the data flow analysis described in
\autoref{sec:rvc}, the model checker is able to successfully check a
large subset of TESLA assertions. As a concrete reference, it is able to
produce the same results as the hand-coded lock usage analyses from
\autoref{sec:hand-coded}.

The model checker will produce imprecise results on any assertion that
contains a field assignment event, and on an assertion with return value
constraints if the function return values are not inferrable from static
control flow. However, it is worth noting that the result of an
imprecise result is simply to leave the original TESLA assertions in
place---they can still be checked at runtime.

\subsection{Limitations and Improvements} \label{sec:model-limits}

\subsubsection{Performance}

Generally speaking, running the model checker is computationally
expensive. However, it is designed to check shorter event paths first,
such that a counterexample can be generated as soon as possible if one
exists (the other benefit of this approach is that shorter
counterexamples are easier for the user to understand).

In practical terms, this means that assertions that have a
counterexample can be checked a great deal faster than those that do
not---if there is no counterexample, then every path shorter than the
bounding length must be checked. For example, checking any incorrect
test case from \autoref{sec:hand-coded} with a bound of 5000
instructions takes approximately 15 seconds, while the successful test
cases take around 90 seconds.

\subsubsection{Function Return Inference}

The implementation used to infer function return values from branch
conditions (as described in \autoref{sec:rvc}) is limited in scope---it
will only infer function return values that within the same basic block
as the branch condition in question, and only then if the dependence
between them is composed only of boolean operations.

However, it would be possible for this inference to be extended. One
possible avenue for this improvement would be to allow the inference of
non-boolean function return values. For example, a symbolic execution
system such as KLEE \cite{cadar_klee:_2008} could be used to explore the
range of function return values that lead to a particular branch.
Alternatively, an SMT\footnote{Satisfiability modulo theories}-based
approach such as LAV \cite{vujosevic-janicic_development_2012} could be
applied to express the relevant inferences as an instance of an SMT
problem.

\subsubsection{Field Assignments}

As noted previously, the model checker cannot check any assertion that
contains a structure field assignment. This limitation arises because
field assignments are inherently \emph{value-dependent}---locating the
IR instruction that assigns to a structure field is easily done, but
computing the value assigned is not easy (in the general case).

A TESLA-specific solution to this issue would be to devise a way of
splitting assertions such that statically provable components are proved
where possible, leaving behind components of the assertion that must be
instrumented dynamically. This approach would require major changes to
some TESLA internals, and was found not to be feasible within the scope
of this project (allowing for the work already done).
