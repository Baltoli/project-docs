In this chapter I present the design and implementation of static
analysis mechanisms for TESLA. First, I motivate this work by
implementing a mutual exclusion lock instrumented with TESLA and
demonstrating that performance improvements are possible. I then
describe a set of ``hand-coded'' analyses specific to the lock
structure. Finally, I generalise the analysis to an implementation of a
non-symbolic model checker for TESLA assertions.

\section{Modelling Locks with TESLA} \label{sec:locks}

\begin{displaycquote}[p. 1]{anderson_tesla:_2014}
TESLA exposes run-time behaviour using program instrumentation, illuminating
coverage of complex state machines and detecting violations of specifications.
\end{displaycquote}

\textcite{anderson_tesla:_2014} draw attention to the suitability of
TELSA for modelling and verifying \emph{state machines} within a
program. A simple state machine that is present in a great deal of code
is the mutual exclusion lock---in this section, I develop TESLA
assertions for the usage of these locks and show the possible benefit of
static analysis with respect to runtime performance.
\autoref{fig:spinlock} shows the state machine for a spin-lock
implemented using a mutex with non-blocking acquire and release
operations.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (start) [] {$U$};
    \node[state] (locked) [right=of start] {$L$};
    \node[state,accepting] (done) [right=of locked] {$D$};
    \node[state] (err) [below=of locked] {$E$};

    \path[->] (start) edge node {\texttt{lock OK}} (locked);
    \draw[->] (start) to[in=60,out=120,loop] node {\texttt{lock busy}} (start);
    \path[->] (start) edge node[below left] {\texttt{*}} (err);
    \path[->] (locked) edge node {\texttt{*}} (err);
    \path[->] (locked) edge node {\texttt{unlock}} (done);
    \path[->] (done) edge node {\texttt{*}} (err);
    \draw[->] (err) to[in=240,out=300,loop] node {\texttt{*}} (err);
  \end{tikzpicture}
  \caption{State machine diagram for a mutual exclusion spin-lock}{(with
  states \emph{unlocked} ($U$), \emph{locked} ($L$),
  \emph{done} ($D$) and \emph{error} ($E$))}
  \label{fig:spinlock}
\end{figure}

While the number of states and operations associated with this state
machine is small, asserting correct usage involves temporal properties
over both control- and data-flow. It will therefore be a useful running
example to demonstrate concepts and implementations throughout the rest
of this chapter.

\subsection{Lock Implementation}

A possible implementation of a mutual exclusion lock using the C11
atomics library is given in \autoref{lst:mutex}. The only operations
permitted by the lock are non-blocking acquisition\footnote{Returns immediately
with \mintinline{c}{true} if the lock was acquired, and
\mintinline{c}{false} if it was not.} and release. Using an atomic
member variable with a compare-and-swap function ensures thread-safety.

\begin{listing}[ht]
  \begin{minted}{c}
  struct lock_t {
    _Atomic(bool) locked
  };

  bool lock_acquire(struct lock_t *lock) {
    bool f = false;
    return atomic_compare_exchange_strong(
            &(lock->locked), &f, true);
  }

  void lock_release(struct lock_t *lock) {
    lock->locked = false;
  }
  \end{minted}
  \caption{Implementation of a mutual exclusion lock with C11 atomics}
  \label{lst:mutex}
\end{listing}

A spin-lock as shown in \autoref{fig:spinlock} can be implemented with a
loop around calls to non-blocking acquire:

\begin{minted}{c}
while(!lock_acquire(lock)) {}
\end{minted}

Correct usage of a lock acquired in this way can be summarised
informally by a set of invariants:
\begin{itemize}
  \item Consumers can fail to acquire the lock any number of times
  \item Once the lock is acquired, no more attempts to acquire can be made
  \item The lock is released exactly once after being successfully acquired
\end{itemize}

\subsection{TESLA Assertions}

The properties described previously are well-suited to being expressed as TESLA
assertions---they express temporal relationships between program events (calls
to the functions \mintinline{c}{lock_acquire} and \mintinline{c}{lock_release}).

\autoref{lst:mutex-tesla} shows a TESLA implementation of the spin-lock
usage properties expressed using explicit TESLA automata.
\begin{listing}[ht]
  \begin{minted}{c}
  automaton(acq_rel, lock_t *lock) {
    acquire(lock);
    release(lock);
    tesla_done;
  }

  automaton(acquire, lock_t *lock) {
    ATLEAST(0, lock_acquire(lock) == false);
    lock_acquire(lock) == true;
    tesla_done;
  }

  automaton(release, lock_t *lock) {
    returnfrom(lock_release(lock));
    tesla_done;
  }
  \end{minted}
  \caption{Mutex lock properties expressed using TESLA}
  \label{lst:mutex-tesla}
\end{listing}

\subsection{Performance Overhead}

The lock assertions can be used to experimentally demonstrate the
performance overhead of using TESLA instrumentation---this motivates the
removal of safe TESLA assertion code using static analysis.

\subsubsection{Experimental Setup}

The benchmark code used in this demonstration creates a number of
threads, each of which attempts to sort a randomly chosen interval of a
large shared array. Threads access the array under mutual exclusion,
protected by a lock as described in \autoref{lst:mutex}---this creates
contention on the lock, dependent on the number of executing threads.

A single TESLA assertion is added to the benchmark to assert the correct
usage of the mutual exclusion lock on the shared array. Two versions of
the program are generated---one with the TESLA instrumentation added,
and the other without. Both versions are compiled using release build
settings.

Both programs were run with the same parameters (threads sort an
interval of size \num{15000} from a larger array of size \num{500000},
and the number of threads was varied from 8 to 40), with results
averaged over 5 runs of the program.

The benchmarks were run on a dedicated server (Intel Xeon E5-1620
\SI{3.6}{\GHz}, 8 cores, 64GB of RAM) running FreeBSD 11.

\subsubsection{Results}

The uninstrumented binary is 25\% smaller than the instrumented binary
(\num{19.1} KiB vs. \num{25.3} KiB).

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      title={Effect of contention on benchmark runtime},
      width=0.85\textwidth,
      xlabel={No. of Threads},
      ylabel={Runtime (s)},
      xmin=5,xmax=43,
      ymin=0,ymax=70,
      xtick={8,16,24,32,40},
      legend pos=north west,
      ymajorgrids=true,
      grid style=dashed,
      cycle list/Dark2,
    ]
      \addplot+[mark=x]
      table [x =x, y =sy, y error =se]{data/locks_bench.dat};

      \addplot+[mark=x]
      table [x =x, y =iy, y error =ie]{data/locks_bench.dat};
      \legend{Uninstrumented,Instrumented}
    \end{axis}
  \end{tikzpicture}
  \caption{Runtime of instrumented and uninstrumented benchmarks at
  varying levels of lock contention}
  \label{fig:locks-bench}
\end{figure}

The results from running the two benchmark programs as described above
are shown in \autoref{fig:locks-bench}. At low levels of contention
there is little difference between the programs; this is because the
TESLA instrumentation code is only executed during acquisitions and
releases of the lock. However, at higher levels of contention more time
is spent in the TESLA instrumentation code, and the instrumented version
becomes slower relative to the uninstrumented version.

If provably safe assertions lie on a frequently executed code path, then
a runtime performance improvement is likely. A decrease in binary size
is also likely, even if the assertions are executed only infrequently.

\section{Hand-Coded Static Analysis} \label{sec:hand-coded}

The first approach taken to static analysis of TESLA assertions was to develop
\textquote{special-cased} assertions that attempt to prove properties only for a
single assertion (in this case, \mintinline{c}{acq_rel}).

Because TESLA assertions describe safety properties of programs, we
perform analyses to find program structure that could cause the
assertion to fail. If none are found, then the assertion will never fail
at runtime, and it is safe to remove the instrumentation code.

To implement this analysis, a set of cases in which the invariants described
previously could possibly fail was compiled. Some of the simpler safety
violations for \mintinline{c}{acq_rel} are:
\begin{itemize}
  \item Either of the lock interface functions have their address taken
  \item One or both of the functions are not called at all
  \item There is no branch on the result of a call to
  \mintinline{c}{lock_acquire}
\end{itemize}

In order to check that these safety properties are not violated, I implemented a
collection of LLVM \cite{lattner_llvm:_2002} analysis passes that each check a
single safety property. 

As well as these passes, I implemented a test suite of programs that use
the lock interface. Each potential safety violation identified occurs at
least once in the test suite; they therefore serve as a litmus test for
correctness of an analysis. There are currently 16 orthogonal test cases
implemented. A more comprehensive testing effort could perhaps involve
automatic generation of test cases or a fuzzing mechanism to expose
bugs.

\subsection{Results}

Using the collection of hand-coded analyses, each case in the test suite
can be correctly classified in less than \num{0.01}\si{\second} (though
this time would increase with the size of the program being analysed).

While there are some advantages to writing assertion safety analyses in
this way, it is far from an ideal approach to the problem. The key
problems are:
\begin{description}
  \item[Development Time] Developing the LLVM analysis passes takes a
    long time (even allowing for the time spent developing
    \textquote{infrastructure} code).
  \item[Inflexibility] Even a small change to the assertions being
    analysed can mean a large change to the analysis being applied.
  \item[Duplicate Logic] The assumptions made in the assertions must be
    duplicated and spread across multiple passes.
\end{description}

In order to address these issues, we require a method for checking
assertions that can be built once \textquote{up front}, can be applied
to any TESLA assertions regardless of the properties that they encode
and that does not rely on any specific knowledge of the assertion being
checked.

\section{Formalising TESLA Assertions} \label{sec:formal}

In order to generalise the hand-coded analyses to arbitrary assertions,
it is necessary to define a more abstract model of the semantics of
TESLA assertions and the programs to which they are applied. In
particular, the failure conditions for arbitrary assertions must be
defined (instead of being hand-coded by the assertion developer).

TESLA assertions \textcquote[p. 3]{anderson_tesla:_2014}{have a natural
expression as finite-state automata that can be mechanically woven into a
program}. However, the exact manner in which these automata are constructed is
only touched upon briefly in the paper. In this section, I define the
semantics of TESLA assertions by providing an explicit translation into
finite-state automata.

The automata constructions given in this section are nondeterministic, with
$\varepsilon$-transitions in some places. It is worth noting the well-known
result that a non-deterministic automaton with $n$ states can always be
converted to an equivalent deterministic automaton with up to $2^n$ states
\cite{rabin_finite_1959}. However, in practice the automata constructed using
the methods described in this section do not experience this exponential
increase in size.

\subsection{Program Events}

As described in \autoref{sec:assertions}, TESLA expresses temporal relationships
between individual program events (function calls, assertion sites
etc.). These events are the building blocks from which an automaton is
constructed.

Program events have no recursive structure (they define only an event
category and associated metadata). As a result, the automata they define
are very simple.  \autoref{fig:event-auto} shows the constructed
automaton for an arbitrary program event $e$---it has a single
transition from the initial state to the accepting state, labelled by
the event $e$.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (start) [] {$q_0$};
    \node[state,accepting] (end) [right=of start] {$q_1$};
    %\node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \path[->] (start) edge node {$e$} (end);
  \end{tikzpicture}
  \caption{Program event automaton}
  \label{fig:event-auto}
\end{figure}

The structure of this automaton is the same no matter what event $e$ it
was constructed for, and it implicitly captures all the metadata
associated with $e$. In \autoref{sec:checking} I give a full description
of how these properties are used to check properties of a program.

\subsection{Composition}

There are two ways in which TESLA automata may be composed---sequential
ordering and disjunction. The TESLA source code makes reference to a
conjunction operation on automata, but it is not fully
implemented.\footnote{The protocol buffer format for assertions allows
for the extra boolean operation type, but using it in an assertion is
unsupported.} These assertions have recursive structure (i.e.  they
contain other automata), and so their constructed automata are defined
as compositions of other automata.

By convention, sub-automata are shown inside dashed boxes. Accepting states
inside these boxes are the accepting states of the sub-automaton, and dotted
lines indicate transitions that are internal to the sub-automaton.

\subsubsection{Sequential Ordering}

The primary temporal relationship TESLA can express is sequential
ordering. Sequence assertions specify an arbitrary list of events that
must happen in order, along with an upper and lower bound on the number
of times the sequence may be repeated (the upper bound may be infinite).

A sequence that occurs exactly once simply links each sub-automaton's
accepting state to the next's initial state with an
$\varepsilon$-transition.  \autoref{fig:seq-one-auto} shows this
construction for two sub-automata.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below=of start] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [right=of end2] (realend) {$q1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (end2) edge node {$\varepsilon$} (realend);
    \draw[->,out=270,in=90] (end.south) to node[above]{$\varepsilon$} (start2.north);
  \end{tikzpicture}
  \caption{Single repetition sequence automaton}
  \label{fig:seq-one-auto}
\end{figure}

From a single repetition, an automaton that can recognise an infinite
number is obtained by adding an $\varepsilon$-transition back from the
accepting state to the initial state (as shown in
\autoref{fig:seq-inf-auto}).

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below=of start] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [right=of end2] (realend) {$q_1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (end2) edge node {$\varepsilon$} (realend);
    \draw[->,out=270,in=90] (end.south) to node[above]{$\varepsilon$} (start2.north);

    \draw[->,looseness=1.2,out=90,in=45] (realend.north) to node[above]{$\varepsilon$} (realstart.north east);
  \end{tikzpicture}
  \caption{Infinite repetition sequence automaton}
  \label{fig:seq-inf-auto}
\end{figure}

If the upper bound is finite, copies of the entire sequence are chained
together to form the overall automaton. The copies in the accepting
range\footnote{i.e. those where the number of repetitions is greater
than or equal to the lower bound and less than the upper bound.} have an
$\varepsilon$-transition to the final accepting state. Writing automata
with a large but finite number of repetitions has a direct effect on
program size as a consequence of this construction.

\subsubsection{Disjunction}

TESLA can also express disjunction of sub-automata.
\autoref{fig:disj-auto} shows how sub-automata can be composed in
\textquote{parallel} to construct an automaton that accepts if any of
its sub-automata do.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [above right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below right=of realstart] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [above right=of end2] (realend) {$q1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (realstart) edge node[below left] {$\varepsilon$} (start2);
    \path[->] (end) edge node {$\varepsilon$} (realend);
    \path[->] (end2) edge node[below right] {$\varepsilon$} (realend);
  \end{tikzpicture}
  \caption{Disjunction automaton}
  \label{fig:disj-auto}
\end{figure}

\section{Model Checking TESLA} \label{sec:checking}

In \autoref{sec:formal} I gave a translation from TESLA assertions to
nondeterministic finite automata with transitions labeled with program
event assertions. These automata act as \emph{specifications} for a
program. To check whether a program is correct with regard to its
specifications is similar to a model checking problem in the style of
\textcite{clarke_design_1982}:

\begin{displaycquote}[p. 2]{clarke_design_1982}
  ...mechanically determine if the system meets a specification expressed in
  propositional temporal logic.
\end{displaycquote}

In this section I describe the methods used to check a program against
its specifications as derived from TESLA assertions. I first describe an
SMT-based algorithm for computing data flow for a program execution.
Then, I apply this together with a form of bounded model checking to
check a program against its specification automata. Finally, I discuss
the limitations and potential improvements that could be made to this
approach.

\subsection{Data Flow Inference} \label{sec:rvc}

Because TESLA allows for data flow properties to be asserted, a mechanism to do
so statically is required for the model checker to be fully useful. The two
forms of data flow assertion allowed by TESLA are constraints on the arguments
passed to a function, and on the value returned by a function call. The dynamic
implementation of TESLA includes code for mapping from an abstract
representation of function arguments onto LLVM values (as this is required to
insert instrumentation code). This code is reused in the model checker, and so
the model checker only has to be able to check function return values.

Stated more formally, the property we are interested in checking is
\textquote{on a particular execution path, can we infer that a function call
returned a fixed value?}. In this section, I describe an algorithm for
performing this inference by making use of an SMT\footnote{Satisfiability Modulo
Theories} encoding of LLVM IR.

\subsubsection{Encoding LLVM IR as SMT Formulae}

In \autoref{sec:smt} I gave an overview of SMT methods, their history and
relevant terminology. Building on this background, in this section I describe
how an LLVM function can be encoded as an SMT problem that when solved gives a
solution to the function return value inference problem described above.

Because LLVM IR is expressed in SSA\footnote{Static Single Assignment} form, it
admits a relatively simple encoding as SMT formulae. For example, the LLVM
instruction \mintinline{llvm}{%3 = add i32 %1, %2} can be seen as a formulae
stating that $ \%_3 = \%_1 + \%_2 $, whatever interpretation is given to the
values $ \%_1 $ and $ \%_2 $. This encoding relies on a particular background
theory (for example, the theory of finite bit vectors---one leading
implementation of which is Boolector \cite{brummayer_boolector:_2009}) to supply
the semantics of $ + $ and other operations. All of the LLVM binary and
comparison operators can be encoded into interpreted SMT functions using this
method.

While it is possible to provide a defined interpretation of some LLVM values, it
is more interesting to consider the ones where we cannot. We have no way of
supplying an interpretation for a function call or a load from memory, for
example. Instructions in this class are encoded as uninterpreted constants in
the same background theory---they will be assigned values in a satisfying model.

A particular execution path through a function is given by a sequence of basic
blocks from entry to termination (through ordinary return or otherwise). From
this execution path we are able to determine the truth values of each branch
condition---these branch conditions uniquely determine control flow and vice
versa. Each of these truth values can then be added to the SMT interpretation of
the IR as an assertion.

The result of applying this translation to a particular execution path is an SMT
instance such that when a model is found, it may give a valuation to the return
value of function calls. It is possible that no valuation for a function call is
found (for example, if no branches depend on its return value), or that several
models are possible. Because TESLA assertions specify a fixed value for a
function return value, we must check that exactly one model is possible---this
can be done by solving an augmented problem that includes the negation of the
original solution as assertions. For example, if \texttt{\%3 = 12} is identified
as a solution, adding \texttt{\%3 != 12} as an assertion causes the problem to
become unsatisifiable if there was only one possible model.

Finally, after translating a function execution and finding a unique
model, we are left with a mapping from call sites to fixed return values
on the execution.  \autoref{fig:llvm-smt} contains an inlined execution
trace taken from the mutex test suite, and \autoref{fig:smt-example}
shows the translation of this IR into an SMT program (given using
SMT-LIB2 standardised syntax \cite{BarST-SMT-10}).

\begin{listing}
  \begin{minted}{llvm}
define i32 @trace_main_5() {
  call void (...)* @__tesla_inline_assertion(...)
  call void @__entry_stub_do_work()
  %2 = call i1 @__entry_stub_lock_acquire(...)
  ; locking code omitted
  br i1 %5, label %__tesla_sink, label %lock_acquire.exit

lock_acquire.exit: ; preds = %6
  %7 = call i1 @__return_stub_lock_acquire(...)
  %8 = xor i1 %7, true
  br i1 %8, label %__tesla_sink, label %do_work.exit

do_work.exit: ; preds = %lock_acquire.exit
  call void @__entry_stub_lock_release(...)
  call void @__return_stub_lock_release(...)
  call void @__return_stub_do_work()
  ret i32 0

__tesla_sink: ; preds = %lock_acquire.exit, %1
  unreachable
}
  \end{minted}
  \caption{LLVM IR to be translated into an SMT problem}
  \label{fig:llvm-smt}
\end{listing}

\begin{listing}
  \begin{minted}{smt2}
(declare-fun |%5| () Bool)
(declare-fun |%7| () Bool)
(define-fun |%8| () Bool (xor |%7| true))
(assert (not |%5|))
(assert (not |%8|))
  \end{minted}
  \caption{SMT translation of LLVM IR}
  \label{fig:smt-example}
\end{listing}

\subsubsection{Implementation}

Implementing the algorithm described above requires several transformations to
be made to an LLVM function before it can be transformed to its SMT
representation. First, because execution is modelled as a sequence of basic
blocks, the function must be completely inlined. This is easily achieved using
existing LLVM library code (with the caveat that infinite recursion can only be
inlined up to a finite depth).

Once the function has been inlined, all of its call sites are removed---this
means we lose information about arguments passed and values returned. To remedy
this problem, calls to stub functions are added before and after each call site
to be inlined. Each stub function receives the same arguments as the call being
made, and the return value of the call is replaced by the return value of the
``after'' stub. The stub functions are not inlined, preserving call graph
information in the inlined function.

Execution sequences are generated from the inlined function by walking its
control flow graph to a specified finite depth---this finiteness condition is
addressed further in \autoref{sec:mc}. Repeated basic blocks from loops in the
graph are handled by simply duplicating the blocks.

From these execution sequences, the Z3 SMT solver \cite{de_moura_z3:_2008} is
used to construct and solve the SMT problem. Z3 was chosen as a
production-quality SMT implementation with a well-documented C++ API.

\subsection{Model Checking Algorithm} \label{sec:mc}

Given the SMT-based mechanism for determining function return values described
above, we can now define a model checking algorithm for TESLA assertions. This
algorithm is defined in terms of finite traces over an LLVM function, together
with the finite state machine translation of an assertion given in
\autoref{sec:formal}.

\subsubsection{Finite Traces}

TESLA assertions are \emph{bounded} by beginning and end events. In the model
checker, for ease of implementation we consider only assertions bounded by entry
and exit to the same function. Possible executions are then sequences of basic
blocks from the entry of this function to an exit (after inlining has been
applied as far as possible).

The model checker generates all possible traces through the inlined bounding
function up to a given length maximum length---while this is unsound from a
theoretical perspective, it is often the case that counterexamples are generated
relatively quickly (as by searching shorter traces first, minimal
counterexamples are found first).

On each of these generated finite traces, we compute the return value
constraints using Z3 as described previously. Then, we pass the sequence of
instructions in the trace to the specification automaton to be checked. The
acceptance criteria for a sequence of instructions is given in the rest of this
section.

\subsubsection{Single-Edge Acceptance}

First, we define a single-edge acceptance criterion that defines when an LLVM
instruction is accepted by an edge in the specification automaton. All of the
relevant program events are encoded as function calls---either to stub functions
that preserve the call graph after inlining, or to the TESLA instrumentation
hook function. Instructions that are not function calls can therefore be
ignored. Then, we can specify when an edge in the specification automaton
accepts a function call instruction (based on the type of the edge) as follows:
\begin{description}
  \item[Function Event] If the call is to an entry stub function (or an exit
    stub function with no associated return value), the function
    names and arguments must match. If it is to an exit stub function with a
    return value specified, the mapping obtained from the SMT solver must
    contain that return value.
  \item[Assertion Site] The location specified by the parameters to the TESLA
    instrumentation hook must match the location contained in the assertion site
    event.
\end{description}

One subtlety to this approach is that not all function call instructions will be
accepted in a given state. In some cases, this is acceptable---if the relevant
TESLA assertion does not mention the called function, then it can safely be
ignored. However, if the assertion does mention the called function but it is
not accepted by a state, then dynamic TESLA instrumentation will throw an error.
The solution to this is to enumerate all the edges of the specification
automaton before checking starts---this gives the collection of all functions
mentioned by the automaton, and we can therefore detect these erroneous
instructions.

\subsubsection{Function Acceptance}

Given a criterion for single-edge acceptance of an LLVM instruction, the next step
is to define when a whole function is accepted by the same automaton.

An initial (and partially inadequate) definition is to say that a function is
accepted by an automaton if and only if every trace through the function
from entry to exit reaches an accepting state in the specification automaton.
This definition is reminiscent of the definition of satisfaction for LTL, where
a formula is satisfied over a structure if and only if it is on all possible
linear paths in that structure. However, this fails to capture an important
feature of TESLA assertions:
\begin{description}
  \item[Non-termination] Programs with TESLA assertions may never
    terminate. This is perfectly valid---as long as the program never
    performs an event not permitted by an automaton, it will not fail
    its TESLA assertions.
\end{description}

Non-termination is added to this definition by including all traces that enter
an infinite loop. These paths may not include an accepting state, and so a path
with an infinite loop satisfies the specification as long as the path does not
contain an event forbidden by the automaton.

\subsubsection{Implementation}

As described previously, we consider only finite traces To implement the definition given previously, the notion of
\textquote{infinite loop} must be sensibly defined in the context of
bounded paths. To do this, we generate every path through the event
graph of length $\leq k$, classifying each as either terminating,
looping or incomplete:
\begin{description}
  \item[Terminating] paths are those that reach the end of the bounding
    interval in $k$ or fewer steps.
  \item[Looping] paths have a suffix made up of more than one
    repetition of a shorter suffix (this characterises infinite loops
    because if the shorter suffix can be repeated more than once, it can
    be repeated any number of times).
  \item[Incomplete] paths are not terminating or looping.
\end{description}

Then to check whether the specification automaton is a model for the
event graph, each terminating and looping path is checked against the
automaton using the acceptance criteria given above. If every path is
accepted by the automaton, then the assertion always holds---the
instrumentation for the assertion can therefore be safely removed from
the program.

\subsection{Limitations and Improvements} \label{sec:model-limits}

\subsubsection{Performance}

Generally speaking, running the model checker is computationally
expensive. However, it is designed to check shorter event paths first,
such that a counterexample can be generated as soon as possible if one
exists (the other benefit of this approach is that shorter
counterexamples are easier for the user to understand).

In practical terms, this means that assertions that have a
counterexample can be checked a great deal faster than those that do
not---if there is no counterexample, then every path shorter than the
bounding length must be checked. For example, checking any incorrect
test case from \autoref{sec:hand-coded} with a bound of 5000
instructions takes approximately 15 seconds, while the successful test
cases take around 90 seconds.

\subsubsection{Field Assignments}

As noted previously, the model checker cannot check any assertion that
contains a structure field assignment. This limitation arises because
field assignments are inherently \emph{value-dependent}---locating the
IR instruction that assigns to a structure field is easily done, but
computing the value assigned is not easy (in the general case).

A TESLA-specific solution to this issue would be to devise a way of
splitting assertions such that statically provable components are proved
where possible, leaving behind components of the assertion that must be
instrumented dynamically. This approach would require major changes to
some TESLA internals, and was found not to be feasible within the scope
of this project (allowing for the work already done).
