In this chapter I present the design and implementation of static analysis
mechanisms for TESLA. First, I motivate this work by implementing a mutual
exclusion lock instrumented with TESLA and demonstrating that performance
improvements are possible by removing TESLA instrumentation code. I then
describe a set of ``hand-coded'' analyses specific to the lock structure.
Finally, I generalise the analysis to an implementation of a non-symbolic model
checker for TESLA assertions.

\section{Modelling Locks with TESLA} \label{sec:locks}

\begin{displaycquote}[p. 1]{anderson_tesla:_2014}
TESLA exposes run-time behaviour using program instrumentation, illuminating
coverage of complex state machines and detecting violations of specifications.
\end{displaycquote}

\textcite{anderson_tesla:_2014} draw attention to the suitability of TESLA for
modelling and verifying \emph{state machines} within a program. A simple state
machine that is present in a great deal of code is the mutual exclusion
lock---in this section, I develop TESLA assertions for the usage of these locks
and show the possible benefit of static analysis with respect to runtime
performance. \autoref{fig:spinlock} shows the state machine for a spin-lock
implemented using a mutex with non-blocking acquire and release operations.

\begin{figure}
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (start) [] {$U$};
    \node[state] (locked) [right=of start] {$L$};
    \node[state,accepting] (done) [right=of locked] {$D$};
    \node[state] (err) [below=of locked] {$E$};

    \path[->] (start) edge node {\texttt{lock OK}} (locked);
    \draw[->] (start) to[in=60,out=120,loop] node {\texttt{lock busy}} (start);
    \path[->] (start) edge node[below left] {\texttt{*}} (err);
    \path[->] (locked) edge node {\texttt{*}} (err);
    \path[->] (locked) edge node {\texttt{unlock}} (done);
    \path[->] (done) edge node {\texttt{*}} (err);
    \draw[->] (err) to[in=240,out=300,loop] node {\texttt{*}} (err);
  \end{tikzpicture}
  \caption{State machine diagram for a mutual exclusion spin-lock}{(with
  states \emph{unlocked} ($U$), \emph{locked} ($L$),
  \emph{done} ($D$) and \emph{error} ($E$))}
  \label{fig:spinlock}
\end{figure}

While the number of states and operations associated with this state machine is
small, asserting correct usage involves temporal properties over both control-
and data-flow. It will therefore be a useful running example throughout the rest
of this chapter.

\subsection{Lock Implementation}

A possible implementation of a mutual exclusion lock using the C11
atomics library is given in \autoref{lst:mutex}. The only operations
permitted by the lock are non-blocking acquisition\footnote{Returns immediately
with \mintinline{c}{true} if the lock was acquired, and
\mintinline{c}{false} if it was not.} and release. Using an atomic
member variable with a compare-and-swap function ensures thread-safety.

\begin{figure}
  \begin{minted}{c}
  struct lock_t {
    _Atomic(bool) locked
  };

  bool lock_acquire(struct lock_t *lock) {
    bool f = false;
    return atomic_compare_exchange_strong(
            &(lock->locked), &f, true);
  }

  void lock_release(struct lock_t *lock) {
    lock->locked = false;
  }
  \end{minted}
  \caption{Implementation of a mutual exclusion lock with C11 atomics}
  \label{lst:mutex}
\end{figure}

A spin-lock as shown in \autoref{fig:spinlock} can be implemented with a
loop around calls to non-blocking acquire:

\begin{minted}{c}
while(!lock_acquire(lock)) {}
\end{minted}

Correct usage of a lock acquired in this way can be summarised
informally by a set of invariants:
\begin{itemize}
  \item Consumers can fail to acquire the lock any number of times
  \item Once the lock is acquired, no more attempts to acquire can be made
  \item The lock is released exactly once after being successfully acquired
\end{itemize}

\subsection{TESLA Assertions}

The properties described previously are well-suited to being expressed as TESLA
assertions---they express temporal relationships between program events (calls
to the functions \mintinline{c}{lock_acquire} and \mintinline{c}{lock_release}).

\autoref{lst:mutex-tesla} shows a TESLA implementation of the spin-lock
usage properties written using explicit TESLA automata.
\begin{figure}
  \begin{minted}{c}
  automaton(acq_rel, lock_t *lock) {
    acquire(lock);
    release(lock);
    tesla_done;
  }

  automaton(acquire, lock_t *lock) {
    ATLEAST(0, lock_acquire(lock) == false);
    lock_acquire(lock) == true;
    tesla_done;
  }

  automaton(release, lock_t *lock) {
    returnfrom(lock_release(lock));
    tesla_done;
  }
  \end{minted}
  \caption{Mutex lock properties expressed using TESLA}
  \label{lst:mutex-tesla}
\end{figure}

\subsection{Performance Overhead}

The lock assertions can be used to experimentally demonstrate the performance
overhead of using TESLA instrumentation, motivating the removal of safe TESLA
assertion code using static analysis.

\subsubsection{Experimental Setup}

The benchmark code used in this experiment created a number of
threads, each of which attempted to sort a randomly chosen interval of a
large shared array. Threads accessed the array under mutual exclusion,
protected by a lock as described in \autoref{lst:mutex}---this created
contention on the lock, dependent on the number of executing threads.

A single TESLA assertion was added to the benchmark to assert the correct usage
of the lock. Two versions of the program were compiled---one with the TESLA
instrumentation added, and the other without. Both versions were compiled using
release build settings.

Both programs were run with the same parameters (threads sort an interval of
size \num{15000} from a larger array of size \num{500000}, and the number of
threads was varied from 8 to 40), with results averaged over 5 runs of the
program. The benchmarks were run on a dedicated server (Intel Xeon E5-1620
\SI{3.6}{\GHz}, 8 cores, 64GB of RAM) running FreeBSD 11.

\subsubsection{Results}

The uninstrumented binary is 25\% smaller than the instrumented binary
(\num{19.1} KiB vs. \num{25.3} KiB).

\begin{figure}
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      title={Effect of contention on benchmark runtime},
      width=0.85\textwidth,
      xlabel={No. of Threads},
      ylabel={Runtime (s)},
      xmin=5,xmax=43,
      ymin=0,ymax=70,
      xtick={8,16,24,32,40},
      legend pos=north west,
      ymajorgrids=true,
      grid style=dashed,
      cycle list/Dark2,
    ]
      \addplot+[mark=x]
      table [x =x, y =sy, y error =se]{data/locks_bench.dat};

      \addplot+[mark=x]
      table [x =x, y =iy, y error =ie]{data/locks_bench.dat};
      \legend{Uninstrumented,Instrumented}
    \end{axis}
  \end{tikzpicture}
  \caption{Runtime of instrumented and uninstrumented benchmarks at
  varying levels of lock contention}
  \label{fig:locks-bench}
\end{figure}

The results from running the two benchmark programs as described above are shown
in \autoref{fig:locks-bench}. At low levels of contention there is little
difference between the programs---this is because the TESLA instrumentation code
is only executed during acquisitions and releases of the lock. However, at
higher levels of contention more time is spent in the TESLA instrumentation
code, and the instrumented version becomes slower relative to the uninstrumented
version.

If provably safe assertions lie on a frequently executed code path, then
a runtime performance improvement is observed. A decrease in binary size
is also observed. This benchmark is a useful demonstration, but does not address
the key question of \emph{why} TESLA imposes runtime overhead on a
program---\autoref{sec:perf-analysis} addresses this question in detail.

\section{Hand-Coded Static Analysis} \label{sec:hand-coded}

The first approach taken to static analysis of TESLA assertions was to develop
\textquote{special-cased} assertions that attempt to prove properties only for a
single assertion (in this case, \mintinline{c}{acq_rel}).

Because TESLA assertions describe safety properties of programs, we
perform analyses to find program structure that could cause the
assertion to fail. If none are found, then the assertion will never fail
at runtime, and it is safe to remove the instrumentation code.

To implement this analysis, a set of cases in which the invariants described
previously could possibly fail was compiled. Some of the simpler safety
violations for \mintinline{c}{acq_rel} are:
\begin{itemize}
  \item Either of the lock interface functions have their address taken
  \item One or both of the functions are not called at all
  \item There is no branch on the result of a call to
  \mintinline{c}{lock_acquire}
\end{itemize}

In order to check that these safety properties are not violated, I implemented a
collection of LLVM \cite{lattner_llvm:_2002} analysis passes that each check a
single safety property. 

As well as these passes, I implemented a test suite of programs that use the
lock interface. Each potential safety violation identified occurs at least once
in the test suite; they therefore serve as a litmus test for correctness of an
analysis. There are currently 16 orthogonal test cases implemented. A more
exhaustive testing effort could perhaps involve automatic generation of test
cases or a fuzzing mechanism to expose bugs.

\subsection{Results}

Using the collection of hand-coded analyses, each case in the test suite
can be correctly classified in less than \num{0.01}\si{\second} (though
this time would increase with the size of the program being analysed).

While there are some advantages to writing assertion safety analyses in
this way, it is far from an ideal approach to the problem. The key
problems are:
\begin{description}
  \item[Development Time] Writing and testing the LLVM analysis passes takes a
    long time (even allowing for the time spent developing
    \textquote{infrastructure} code).
  \item[Inflexibility] Even a small change to the assertions being
    analysed can mean a large change to the analysis being applied.
  \item[Duplicate Logic] The assumptions made in the assertions must be
    duplicated and spread across multiple passes.
\end{description}

In order to address these issues, we require a method for checking
assertions that can be built once \textquote{up front}, can be applied
to any TESLA assertions regardless of the properties that they encode
and that does not rely on any specific knowledge of the assertion being
checked.

\section{Formalising TESLA Assertions} \label{sec:formal}

To generalise the hand-coded analyses to arbitrary assertions, a more abstract
model of the semantics of TESLA assertions and the programs to which they are
applied needs to be defined. In particular, the failure conditions for arbitrary
assertions must be defined (instead of being hand-coded by the assertion
developer).

TESLA assertions \textcquote[p. 3]{anderson_tesla:_2014}{have a natural
expression as finite-state automata that can be mechanically woven into a
program}. However, the exact manner in which these automata are constructed is
not given in full in the paper. In this section, I define the semantics of TESLA
assertions by providing the full translation into finite-state automata.

The automata constructions given in this section are nondeterministic with
$\varepsilon$-transitions. It is worth noting the well-known result that a
non-deterministic automaton with $n$ states can always be converted to an
equivalent deterministic automaton with up to $2^n$ states
\cite{rabin_finite_1959}. However, in practice the automata constructed using
the methods described in this section do not experience an exponential increase
in size.

\subsection{Program Events}

Single program events have no recursive structure (they define only an event
category and associated metadata). As a result, the automata they define are
very simple. \autoref{fig:event-auto} shows the constructed automaton for an
arbitrary program event $e$---it has a single transition from the initial state
to the accepting state, labelled by the event $e$.

\begin{figure}
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (start) [] {$q_0$};
    \node[state,accepting] (end) [right=of start] {$q_1$};
    %\node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \path[->] (start) edge node {$e$} (end);
  \end{tikzpicture}
  \caption{Program event automaton}
  \label{fig:event-auto}
\end{figure}

The structure of this automaton is the same no matter what event $e$ it was
constructed for, and it captures all the metadata associated with $e$. In
\autoref{sec:checking} I give a full description of how these properties are
used to check properties of a program.

\subsection{Composition}

There are two ways in which TESLA automata may be composed---sequential
ordering and disjunction. The TESLA source code makes reference to a
conjunction operation on automata, but it is not fully
implemented.\footnote{The protocol buffer format for assertions allows
for the extra boolean operation type, but using it in an assertion is
unsupported.} These assertions have recursive structure (i.e.  they
contain other automata), and so their constructed automata are defined
as compositions of other automata.

By convention, sub-automata are shown inside dashed boxes. Accepting states
inside these boxes are the accepting states of the sub-automaton, and dotted
lines indicate transitions that are internal to the sub-automaton.

\subsubsection{Sequential Ordering}

The primary temporal relationship TESLA can express is sequential
ordering. Sequence assertions specify an arbitrary list of events that
must happen in order, along with an upper and lower bound on the number
of times the sequence may be repeated (the upper bound may be infinite).

A sequence that occurs exactly once simply links each sub-automaton's
accepting state to the next's initial state with an
$\varepsilon$-transition.  \autoref{fig:seq-one-auto} shows this
construction for two sub-automata.

\begin{figure}
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below=of start] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [right=of end2] (realend) {$q1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (end2) edge node {$\varepsilon$} (realend);
    \draw[->,out=270,in=90] (end.south) to node[above]{$\varepsilon$} (start2.north);
  \end{tikzpicture}
  \caption{Single repetition sequence automaton}
  \label{fig:seq-one-auto}
\end{figure}

From a single repetition, an automaton that can recognise an infinite
number is obtained by adding an $\varepsilon$-transition back from the
accepting state to the initial state (as shown in
\autoref{fig:seq-inf-auto}).

\begin{figure}
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below=of start] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [right=of end2] (realend) {$q_1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (end2) edge node {$\varepsilon$} (realend);
    \draw[->,out=270,in=90] (end.south) to node[above]{$\varepsilon$} (start2.north);

    \draw[->,looseness=1.2,out=90,in=45] (realend.north) to node[above]{$\varepsilon$} (realstart.north east);
  \end{tikzpicture}
  \caption{Infinite repetition sequence automaton}
  \label{fig:seq-inf-auto}
\end{figure}

If the upper bound is finite, copies of the entire sequence are chained together
to form the overall automaton. The copies in the accepting range\footnote{i.e.
those where the number of repetitions is greater than or equal to the lower
bound and less than or equal to the upper bound.} have an
$\varepsilon$-transition to the final accepting state. Writing automata with a
large but finite number of repetitions has a direct effect on program size as a
consequence of this construction.

\subsubsection{Disjunction}

TESLA can also express \emph{inclusive} and \emph{exclusive} disjunction of
sub-automata. \textcite{anderson_tesla:_2014} specify a cross-product based
construction for the inclusive case, where \texttt{a || b} means that either or
both of \texttt{a} and \texttt{b} can occur. The exclusive case (\texttt{a xor
b}) where only one of \texttt{a} or \texttt{b} may occur is simpler to
construct, and an example is shown in \autoref{fig:disj-auto}.

\begin{figure}
  \centering
  \begin{tikzpicture}[>=latex',initial text={},
                      node distance=3cm,on grid,auto]
    \node[state,initial] (realstart) [] {$q_0$};
    \node[state] (start) [above right=of realstart] {$q_{0,0}$};
    \node[state,accepting] (end) [right=of start] {$q_{1,0}$};

    \node[state] [below right=of realstart] (start2) {$q_{0,1}$};
    \node[state,accepting] [right=of start2] (end2) {$q_{1,1}$};

    \node[draw,dashed,fit=(start) (end), inner sep=0.3cm] {};
    \node[draw,dashed,fit=(start2) (end2), inner sep=0.3cm] {};

    \node[state,accepting] [above right=of end2] (realend) {$q1$};

    \path[dotted,->] (start) edge node {} (end);
    \path[dotted,->] (start2) edge node {} (end2);

    \path[->] (realstart) edge node {$\varepsilon$} (start);
    \path[->] (realstart) edge node[below left] {$\varepsilon$} (start2);
    \path[->] (end) edge node {$\varepsilon$} (realend);
    \path[->] (end2) edge node[below right] {$\varepsilon$} (realend);
  \end{tikzpicture}
  \caption{Inclusive-or automaton}
  \label{fig:disj-auto}
\end{figure}

\section{Model Checking TESLA} \label{sec:checking}

In \autoref{sec:formal} I gave a translation from TESLA assertions to
nondeterministic finite automata with transitions labeled with program
event assertions. These automata act as \emph{specifications} for a
program. Checking whether a program is correct with regard to its
specifications is similar to a model checking problem in the style of
\textcite{clarke_design_1982}:

\begin{displaycquote}[p. 2]{clarke_design_1982}
  ...mechanically determine if the system meets a specification expressed in
  propositional temporal logic.
\end{displaycquote}

In this section I describe the methods used to check a program against
its specifications as derived from TESLA assertions. I first describe an
SMT-based algorithm for computing data flow information for an
individual program execution. Then, I apply this together with a form of
bounded model checking to check a program against its specification
automata. Finally, I discuss the limitations and potential improvements
that could be made to this approach.

\subsection{Data Flow Inference} \label{sec:rvc}

TESLA allows for properties of data flow to be asserted---in particular, the
value of arguments passed to functions and the value returned by a function
call. Checking arguments passed to functions can be performed with only minor
modifications to existing TESLA code, and so in this section I describe only the
algorithm used to check function return values.

Stated formally, the property we are interested in checking is
\textquote{on a particular execution path, can we infer that a function
call returned a fixed value?}. In this section, I describe an algorithm
for performing this inference by translating LLVM functions to SMT
problems.

\subsubsection{Encoding LLVM IR as SMT Formulae}

In \autoref{sec:smt} I gave an overview of SMT methods, their history
and relevant terminology. Building on this background, in this section I
describe how an LLVM function can be translated to an SMT problem that
can be used to solve the return value inference problem described above.

A subset of LLVM IR can be easily translated to an SMT formula.\footnote{At least
for the properties relevant to this problem---a full translation of the
LLVM semantics would be more complex.} For example, the LLVM
instruction \mintinline{llvm}{%3 = add i32 %1, %2} can be seen as a formulae
stating that $ \%_3 = \%_1 + \%_2 $, whatever interpretation is given to the
values $ \%_1 $ and $ \%_2 $. This encoding relies on a particular background
theory (for example, the theory of finite bit vectors) to supply
the semantics of $ + $ and other operations. All of the LLVM binary and
comparison operators can be translated to interpreted SMT functions using this
method.\footnote{Except floating point operations, which are unsupported by
TESLA in general.}

Function calls and loads from memory are translated to uninterpreted
functions---we have no \emph{a priori} knowledge of the value they will
take at runtime, but they can be assigned values in a satisfying model
for the problem.

A single execution path through a function is a finite sequence of basic blocks
starting at the entry block. The blocks executed in the sequence constrain the
values of \emph{branch conditions} (the LLVM values on which conditional
branches are predicated). These constraints are then added to the SMT problem as
assertions.

Applying this translation to a single execution path yields an SMT problem, the
solution to which produces an assignment of values to LLVM variables. It is
possible that some variables are left unconstrained (if no conditional branches
depend on their value), or that multiple values are satisfying assignments. In
order to check whether a valuation is unique for a given variable, we construct
an augmented problem that contradicts the original model. If this problem is
unsatisfiable, the original solution was unique.

Finally, after translating a function execution and finding a unique model, we
are left with a mapping from call sites to fixed return values (on this
execution path).

\subsubsection{Implementation}

Implementing the algorithm described above requires several transformations to
be made to an LLVM function before it can be translated to an SMT
formula. First, because execution is modelled as a sequence of basic
blocks, the function must be completely inlined. This is easily achieved using
existing LLVM library code (with the caveat that infinite recursion can only be
inlined up to a finite depth).

When a function is inlined, all calls to it are removed---this means we lose
information about arguments passed and values returned. This problem is resolved
by adding calls to stub functions before and after each call site to be inlined.
Each stub function receives the same arguments as the call being made, and the
return value of the call is replaced by the return value of the ``after'' stub.
This means that relevant call graph information is preserved in the inlined
function.

Execution sequences are generated from the inlined function by walking its
control flow graph to a specified finite depth---this finiteness condition is
addressed further in \autoref{sec:mc}. Repeated basic blocks from loops in the
graph are handled by simply duplicating the blocks. \autoref{lst:llvm-smt} shows
a single trace taken from one of the programs in the mutex test suite after
these transformations have been applied.\footnote{In this example,
\texttt{\_\_tesla\_sink} is a basic block added to preserve control flow
information.}

\begin{figure}
  \begin{minted}{llvm}
define i32 @trace_main_5() {
  call void (...)* @__tesla_inline_assertion(...)
  call void @__entry_stub_do_work()
  %2 = call i1 @__entry_stub_lock_acquire(...)
  ; locking code omitted
  br i1 %5, label %__tesla_sink, label %lock_acquire.exit

lock_acquire.exit: ; preds = %6
  %7 = call i1 @__return_stub_lock_acquire(...)
  %8 = xor i1 %7, true
  br i1 %8, label %__tesla_sink, label %do_work.exit

do_work.exit: ; preds = %lock_acquire.exit
  call void @__entry_stub_lock_release(...)
  call void @__return_stub_lock_release(...)
  call void @__return_stub_do_work()
  ret i32 0

__tesla_sink: ; preds = %lock_acquire.exit, %1
  unreachable
}
  \end{minted}
  \caption{LLVM IR to be translated into an SMT problem}
  \label{lst:llvm-smt}
\end{figure}

\begin{figure}
  \begin{minted}{smt2}
(declare-fun |%5| () Bool)
(declare-fun |%7| () Bool)
(define-fun |%8| () Bool (xor |%7| true))
(assert (not |%5|))
(assert (not |%8|))
  \end{minted}
  \caption{SMT translation of LLVM IR}
  \label{lst:smt-example}
\end{figure}

The Z3 SMT solver \cite{de_moura_z3:_2008} is used to construct and solve the
SMT problem corresponding to an execution sequence. Z3 was chosen as a
production-quality SMT implementation with a well-documented C++ API, but the
techniques used apply equally well to any SMT solver implementation.
\autoref{lst:smt-example} shows the SMT translation of the LLVM IR in
\autoref{lst:llvm-smt}, given in SMT-LIB standard syntax \cite{BarST-SMT-10}.

\subsection{Model Checking Algorithm} \label{sec:mc}

Given the SMT-based mechanism for determining function return values described
above, a model checking algorithm for TESLA assertions can now be defined. This
algorithm is defined in terms of execution traces over an LLVM function (as
defined previously), along with the finite-state automaton translation of an
assertion given in \autoref{sec:formal}.

\subsubsection{Execution Traces}

TESLA assertions are bounded by beginning and end events. In the model checker,
for ease of implementation we consider only assertions bounded by entry and exit
to the same function. Possible executions are then sequences of basic blocks
that begin at the function's entry block.

The model checker generates all possible executions through the inlined bounding
function up to a given length maximum length. On each of these generated
executions, we compute function return values using Z3 as described previously.
Then, the execution is checked for acceptance against the finite-state automaton
obtained from the original assertion.

If all possible executions are accepted by the automaton, then the assertion
cannot fail at runtime. Its instrumentation code can therefore be removed safely
from the program. If an execution is not accepted by the automaton, then a
\emph{counterexample} has been found---we can demonstrate an execution path on
which the assertion may not hold, and the reasons why it may not hold.
\autoref{lst:counter} shows a counterexample generated from one of the mutex
test programs (the full DOT output for the finite-state automaton has been
omitted for brevity).

\begin{figure}
  \begin{minted}{objdump-nasm}
Unexpected event in state s3:
  return from lock_acquire (return value == 1)

FSM:
  digraph {
    ...
  }

Call stack:
  call: lock_init
  return: lock_init
  call: do_work
  call: lock_acquire
  return: lock_acquire
  call: lock_acquire
  \end{minted}
  \caption{Counterexample trace generated from a mutex test program}
  \label{lst:counter}
\end{figure}

\subsubsection{Checking Execution Traces}

In this section I describe how an execution trace can be checked against a
specification automaton. I first describe how individual state transitions are
checked, and from there define a notion of acceptance for an entire execution
trace.

Each execution trace is a finite sequence of LLVM instructions. For each
instruction in the sequence, the following checks are made:
\begin{itemize}
  \item Is the instruction a function call? (all checkable program events are
    expressed as function calls in the IR---either to entry or return stubs, or
    to the internal TESLA assertion site function).
  \item If it is, is it accepted by any of the edges from the current state?
  \item If none of the edges accept the function call, does there exist an edge
    elsewhere in the automaton that would accept it?
\end{itemize}

Whether or not an individual edge accepts a program event is defined in terms of
the event's type and metadata---if the event's metadata matches the edge's, then
the event is accepted. For edges that specify a function return value, the check
also verifies that the mapping generated from the SMT problem includes a
matching entry.

If an event is not accepted in the current state, but would be in another, then
the assertion has been violated. If it is not accepted in any state, then we
ignore the instruction as a \textquote{don't care} event.

It is now possible to define when an execution trace is accepted by the
specification automaton. As noted previously, traces do not have to be
complete---they may not reach a terminating block for the
function.\footnote{Incomplete traces are required to deal with code that may
enter an infinite loop.} Separate definitions for complete and incomplete traces
must therefore be given.

A complete trace ends in a basic block with no successors, and is accepted if
the state reached after all instructions have been checked is an accepting
state. Incomplete traces are accepted if an accepting state is reachable from
the final state reached. In both cases if an unexpected event occurs, the
execution is not accepted. The difference in semantics between complete and
incomplete traces is discussed in some depth by
\textcite{eisner_reasoning_2003}---in particular, their description of a
\textquote{weak view} corresponds to the checking criteria for incomplete traces
described previously.\footnote{The weak view asserts that
\textcquote[p.29]{eisner_reasoning_2003}{nothing has yet gone wrong}, while the
strong view asserts that an assertion is \textquote{already} satisifed on a
truncated execution path.}

\subsection{Results} \label{sec:model-limits}

The implementation of the algorithms described above was able to correctly check
all the examples from the mutex test suite described in
\autoref{sec:hand-coded}, achieving parity with the less flexible hand-coded
analyses.

\subsubsection{Field Assignments}

As noted previously, the model checker cannot check any assertion that
contains a structure field assignment. This limitation arises because
field assignments are inherently \emph{value-dependent}---locating the
IR instruction that assigns to a structure field is easily done, but
computing the value assigned is not easy (in the general case).

A TESLA-specific solution to this issue would be to devise a way of
splitting assertions such that statically provable components are proved
where possible, leaving behind components of the assertion that must be
instrumented dynamically. This approach would require major changes to
some TESLA internals, and was found not to be feasible within the scope
of this project. The SMT methods for function return value inference may also be
applicable (with some adaptation).
