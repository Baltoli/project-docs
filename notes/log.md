# Part III Project Work Log & Notes

## 24/11/16

* Build TESLA on both remote and local machines - it would be good to be able to
  work on both (if ssh is slow or compile times are a problem).
  * Local - ran into a problem when building. Possibly because we require msan
    for something? Can't get it to build for now - try again later if really
    necessary.
  * Remote - seems to build *a lot* faster than on my laptop. Needs libprotobuf
    installed. Possibly better to wait for cluster access rather than mucking
    around in my home directory to try and install it?

* Cluster login - have been added to the appropriate gorups but need to find out
  how to actually log in / install software / etc.

* Reading code and understanding the structure of TESLA
  * Analyzer - tool for walking over TESLA assertions in a program and
    serializing them to protobuf
    * Main entry point in analyzer/tool.cpp parses command line options etc, then
      builds a clang tool and calls out to it
      * Clang tool takes a compilation database and a list of source paths to work
        on
      * Uses a TeslaActionFactory as an argument to the tool - this builds a
        TeslaAction that runs over the source files. Serializes automata usages to
        a protobuf file / string
    * Vistor class walks over automata descriptions and tries to parse them
  * Common - functionality used by multiple parts of TESLA
    * Class that describes the internal automaton / states / transitions between
    * Protocol buffer specification
    * Automatic name generation for internal components
    * Manifest describes the TESLA instrumentation to perform - can be loaded
      from a file (is this the same format that's dumped out by the analysis
      phase / catted together?)
    * Convenience stuff for debugging
  * Instrumenter -  does the work of adding stuff to compiled IR based on the
    analysis phase
    * Adds to the IR based on the actual TESLA assertions that are made
    * Field reference, function calls, struct assignment, assertions etc are
      defined in this part of the code base
    * Translation from actual program events into automata descriptions
  * Tools - the TESLA binary tools that make up the workflow as described in the
    project documentation
    * `cat` - reads all the automata from the filenames passed in, then combines
      them together into a single manifest (doing error checking - for example,
      two automata with the same name but different contents is an error).
    * `print` - just prints out an automata description to the console in a
      bunch of different formats
    * `get-triple` - just a call to the LLVM function that gets the system
      triple.
  * Tests - for automata, instrumentation, integration, parsing, regression
    * Parsing tests put TESLA assertions into a bunch of different C programs
      and use FileCheck to ensure that the assertion grammar is parsed out
      correctly
    * Integration tests build full example programs and ensure that TESLA
      behaves correctly
    * Regression tests cover examples generated from previously found bugs in
      the system
    * Automata covers working on automata protobufs (either written out
      explicitly or generated from C programs) - e.g. that they can be
      concatenated together & resolved properly etc.
    * Instrumentation tests the interaction of the system with LLVM bitcode
      (i.e. that the correct checks are being added to the bitcode files)

* TESLA workflow summary / idea of how data flows through the system
  * Starts from ordinary C programs with no assertions in them
  * Then they are instrumented by adding TESLA assertions to check some
    property of system behaviour
  * A C file with TESLA instrumentation is then *analysed* by the first part of
    the TESLA workflow - the analysis phase produces a `.tesla` file which
    contains an automaton description (these descriptions contain essentially an
    AST of the assertions contained in the program - examples are in the tests
    directory as FileCheck lines).
  * The C file is also compiled as normal into a .ll file using clang once it
    has been analysed.
  * All the .tesla files generated by the analysis phase are combined together
    using the `cat` utility into one manifest.
  * Then, the single combined manifest is used to instrument the compiled LLVM
    bitcode files (giving a set of augmented LLVM bitcode files).
  * The instrumented files can then be compiled using `llc` into a binary as
    normal, with the TESLA functionality included.

## 2/12/2016

* Got set up on the development server by Khilan - managed to get TESLA building
  and installing into a home directory appropriately.
* Manually worked through compiling a program to use TESLA etc.
* Built a somewhat hacky CMakeLists that lets me compile a _simply-structured_ C
  application into a version that is instrumented with TESLA. At some point will
  need to look into how this can actually be done in practice for a larger code
  base! (Ask Jon Anderson?)
* Begun to look into building some very simple TESLA assertions on a small
  program.

## 3/12/2016

* Continued to work on very simple examples learning to use TESLA. Found that
  the documentation is out of date in a number of places:
  * `TESLA_NOW` is replaced by `TESLA_ASSERTION_SITE`
  * `called` seems to have been replaced by `call` but I'm not sure if this is a
    drop-in replacement.
* Notes on using TESLA:
  * `TESLA_ASSERTION_SITE` refers to the point at which the assertion is written
    in the original program (hence why `previously` and `eventually` are written
    the way they are). It can be used to express more complex interleavings of
    temporal properties by having things before / after it as well.
  * `ANY` takes an argument (`int`, `long long`, `ptr` etc.) to represent the
    type of argument being passed to the function call.
  * The `call` function takes a single parameter - the function call as it would
    be written in the program! This is different to `returnfrom`, which takes an
    extra parameter for the return value. Why can't you do
    `call(foo(ANY(int)))`? Ask Jon.

## 5/12/2016

* Did some more digging into why explicit automata descriptions aren't working
  for me. No real answers yet - the symptom is that I have an undefined name in
  the instrumented LLVM code. Something has inserted a global variable for the
  automaton into the code but has not "expanded" it with a definition. Have
  emailed Jon for clarification / help but no answer yet. The next place to look
  is probably trying to find out what is meant to replace the global variable.

## 15/12/2016

* Still no reply from Jon. Should get Robert to prod him. Looking into why I get
  these linker errors with a much-simplified example. Seems that the
  `tesla_update_state` function is getting called with `my_auto` as an argument,
  which is a global variable in the LLVM IR. This means (probably) that
  something isn't actually populating this global variable with a real value.
  Dig though code and find out where?
* When we end up calling `ExternAutomatonDescrip` to get a global variable,
  the first time we call, there isn't a variable ready. The second time, there
  is and we get it.
* Looks like `BuildAutomatonDescription` is doing what we want but it isn't
  getting called - it is responsible for getting rid of extern specified global
  variables and replacing them with things that actually have an initializer!
* It seems to be called in two separate places in Assertion.cpp - how do these
  different places get triggered? Actually only in one location for the version
  of TESLA I have on my machine (why is this different??) This was different
  because I was building against CTSRD TESLA rather than CADETS TESLA and there
  was some difference in the code for newer commits.
* The path that gets to where we want to be is returning early because there are
  no assertions in the module. How do I add an assertion to the module?
* `TESLA_STRUCT_AUTOMATON` is dead - the actual syntax is to use the automaton
  just like a function call (for example, `eventually(my_auto(a))`)
* Usage: you can't go arbitrarily far down the call stack using `TESLA_WITHIN` -
  it seems to be only within the current function that it's usable. 
* Setting up: managed to get my tesla experimentation work shoved into the TESLA
  source tree so that I can build etc all in the same place. Took a bit of
  working to get CMake not to break but now it works. Next step: modelling
  simple locks.

## 16/12/2016

* Begin to work on getting a very simple model of locks verified. Set up project
  structure etc. Convenience macro for TESLA struct field accesses (might be
  extensible in the future to a full struct macro for ease).
* Implemented a simple lock automaton that ensures that a particular function is
  'well-behaved' with regard to a particular lock (i.e. it acquires the lock at
  some point, then releases it later). This currently catches things like
  releasing without acquiring, acquiring after release. It can't handle a
  deadlock situation yet (can it?). 
* Need to look into why if a thread exits without calling `lock_release`, it
  won't trigger an assertion failure.
* Using previously instead of eventually seems to fix the deadlock problem on
  the lock automata. Also added a check to make sure that acquire calls go
  "F...FT" only.
* Using two or more locks: I think strict mode might be a problem here. How to
  fix this?

## 17/12/2016

* Looking into how I can use `tesla-print` to get `.dot` files for debugging.
  Managed to get graphviz on OS X to output me a file. Workflow is a little bit
  inconvenient though (but obviously no way to view pngs on the server).
* Currently doesn't look like there's an easy way to have a function that acts
  as a thread worker be instrumented from outside of its own definition (or a
  caller), nor for a function to work on *multiple* locks.
* Even shifting stuff one level up the call stack seems to break things a bit -
  why can't I use `acq_rel` from `thread_work` which just calls into
  `thread_say`?
* Seem to have sorted this out - if I use the wider bound of `thread_work` then
  it works, but not the narrow bound of `thread_say`.
* Now have a system for making assertions about several locks in the same
  function (not interleaved though I don't think). Uses a strict sequence.
* At this stage I have a working verifier for a very simple lock that can be
  used to verify acquire-release behaviour for a single lock, multiple locks in
  sequence, or multiple locks interleaved.
* Next step is to think about how best to statically analyse this type of
  structure, and also to look at how locks are implemented internally in (for
  example) FreeBSD (and then to come up with equivalent automata for the real
  locks).
* Also worth thinking about what properties (in a formal sense) this
  implementation allows me to verify.

## 18/12/2016

* Small amount of work looking into the lifetime automata but to no real
  progress - I can get them to compile but their definitions seem to somehow be
  different to regular 'in-function' automata. Shelving this for now.

## 19/12/2016

* Begin looking into how static analysis can be performed on TESLA automata,
  starting with the example of a single lock being acquired and released.
* Structure of a TESLA automaton is described at the highest level by the
  protocol buffer specification ultimately. This gives us the "grammar" by which
  an automaton is described. Can see examples of this as the ouput from the
  `tesla-cat` step of building a program against TESLA.
* Obviously code for working with an automaton in this state is generated by the
  protobuf build step (so should look up how to actually work with this
  generated code).
* A `Manifest` describes all the automata contained in a single file, while an
  `Automaton` is singular (only describes one single set of states and
  transitions).
* Initial effort will be to statically analyse the locking assertions I've built
  over the last few days.
* What do we want to prove about this automata specifically? (in this case I
  think that I do actually want to be specific and see how it can be generalised
  to a more significant structure).
  * The `acq_rel` automaton *should* be generic over any kind of lock simple
    enough to be described with simple atomic acquire / release semantics.
  * For example, a Pthreads mutex could be adapted to this structure by wrapping
    the Pthreads acquire / release functions (should try this at some point by
    making an *almost* identical example to the current `locks.c` experiment.
  * What `acq_rel` asserts is that on any code path, the function will spin
    around 0 or more times failing to acquire the lock, then successfully
    acquires the lock, then releases it.
  * Need to characterise *exactly* what behaviour is allowed and forbidden by
    the automaton as it is currently implemented (by building a set of smaller
    test cases that demonstrate its behaviour - note that `lock_acquire` and
    `lock_free` are *mockable* - they present an interface that can just as well
    be implemented by something that doesn't actually do any locking at all!).
  * Then once I have an informal but demonstrable model of the lock automaton's
    behaviour, I can start to work out exactly how these properties can be
    described (and proved) at the IR level.
  * For this specific analysis of my automaton only, there is no need to really
    work with the TESLA IR at all - instead need to just look for the very
    specific form that instruments an acquire / release cycle.
* Worked out some CMake hackery to allow multiple TESLA executables to share a
  single source file. As far as I can see the solution of building every source
  file for every target executable is necessary - instrumentation will change
  things etc so this is the only way to do it generically (without having custom
  TESLA invocations for every single executable being built). These improvements
  to the TESLA build system allow me to build arbitrary C executables with TESLA
  assertions built in just by calling `add_tesla_executable`.
* Have also begun to do some rebasing and cleanup on the locks branch so that
  when I merge it to master it's not totally horrific to look at.
* Implemented a few small misbehaving programs to demonstrate the kinds of
  behaviour that the lock automata attempt to catch.

## 20/12/2016

* Finished off writing example programs that show the behaviour of my simple
  lock automata (successful / good path as well as several 'failed' examples).
  Still running into the issue that assertions don't seem to care about the
  identity of the pointer they're being called with (`acq_rel(&lock)` is
  equivalent to `acq_rel(&other)` behaviourally - it doesn't seem to matter
  which one is actually acquired and released). Need to work out if there's a
  solution to this (my instinct is that there isn't an easy way to do so because
  of the way instrumentation is added to code).
* One possible hacky workaround is to add a global ID to every lock - then, the
  `lock_X` functions could work on a lock ID rather than directly on a pointer.
  I think this might be easier to reason about, provided that the correct
  guarantees are made of the global lock ID 'repository'.
  * `lock_init` would need to increment the global ID counter, set the field on
    the lock, put the lock itself into an array (by value), then return the id.
  * `lock_acquire` and `lock_release` would need to work on the base pointer +
    offset, rather than on the addresses directly. They could then be modified
    to take an ID (integer) rather than a direct pointer.
  * `lock_free` would then need to perform any necessary cleanup (can't see what
    this would actually be just now).
  * This would mean that initializing a lock would not necessarily be atomic
    (but that's fine I think - just need to do lifecycle things sequentially
    before using locks for real).
  * Doing this might even make it easier to statically analyse locks - working
    out the value of an integer value seems like it would be more amenable than
    chasing pointers.
* Update: this strategy of using IDs rather than pointers isn't totally workable
  with the current implementation. Maybe possible in the future to rip it out
  and design from scratch (but wouldn't be able to use automata quite as
  idiomatically as they currently are).
* So with that in mind, the properties we can observe the `acq_rel` automaton as
  having are (for a *single* lock being used by a function):
  * `lock_acquire` returns false 0 or more times, until it returns true exactly
    once. It is not called again.
  * `lock_release` is called exactly once.
  * Any extra calls to either lock function will fail.
  * Calling `lock_release` before `lock_acquire` has returned true will fail.
* Where in the TESLA workflow should static analysis live?
  * Likely to be in the form of an IR pass to actually perform the analysis (but
    also need some information from the analyser level to know where to apply
    analysis).
  * For now, the analysis will be specific to the `acq_rel` automaton, and so
    all we need to do at the analyser level is find usages / bounds / locks etc
    for each instance of the automaton.
  * So at the point at which static analysis is performed we require:
    * The combined manifest file with the whole-program view of assertions made
    * The uninstrumented `.ll` file that the program was compiled into
  * From these prerequisites, we should then produce a statically-analysed
    version of the manifest that has had verifiable assertions removed (but that
    remains in the same format).
  * The optimised manifest can then be used as a drop-in replacement for the
    non-optimised version (bonus from this is that the program can then be
    instrumented using both versions and their behaviour compares).
* Gist of this is that what we want is really a new TESLA tool (`tesla-static`)
  that takes an bitcode file and a manifest for analysis, then returns a new
  with possibly different contents.
  * Benefit of this is that we're not doing anything unsafe at the bitcode level
    (in this particular model). All we do there is analysis of some kind that
    informs the different manifest.
  * Probably need this to be whole-program analysis. Should therefore
    investigate whether `llvm-link` can be built into the build system (i.e.
    that it plays nicely with instrumentation etc.)
  * It can in fact. I've now updated the TESLA build script to link all the .bc
    files into a single one before instrumenting (and have changed extensions
    etc. to be more correct). Now the TESLA build script will compile the
    program from a single .bc file (and analysis can be done on this
    individually).

## 21/12/2016

* Got the boilerplate set up for the static analysis tool (very similar to
  `tesla-instrument`). It is now able to load a manifest and an IR file from
  disk when it is run.
* Did a bit of tinkering to see what information I can get out of the manifest
  file using the protobuf generated code etc. Seems to be a reasonably easy
  interface to work with (`set_X` for setting fields, `X` for getting fields).
* Now need to work out what kind of interface I want the static analysis to
  have.
  * Will make sense to have a modular system (so that future analyses aren't
    tied directly into the structure of the tool itself and the initial work I'm
    doing here).
  * Then each additional analysis I do can be plugged into the tool with a
    minimum of work.
  * The information that we have at the start is the unmodified manifest file
    and the IR. It makes sense that each 'pass' will get the same things passed
    to it, with the exception that the manifest will be changed between each
    step (as it wouldn't make sense to leave it unchanged and then do every pass
    at once at the end).
  * So it will make sense to have:
    * Base class for manifest passes that defines an interface each conforms to.
    * Builder class that takes a list of instantiated manifest passes and runs
      them one after another in a pipeline.
* Have implemented a pass system that allows for manifest passes to be
  constructed and run on manifests / IR files.
* Now the next problem is how to create a new manifest given the original one.
  Seems to be that modifying in place isn't possible as the `Manifest` class is
  const-ed up pretty heavily. Should look further at `tesla-cat` to work out how
  this could be done. Looks like `ManifestPass::run()` will need to actually
  return a new `Manifest` (which can be passed into the next one in the pipeline
  etc.).
* The analysis for `acq_rel` is an include / exclude decision. So what needs to
  be done is walk the root automata for things that are `acq_rel` (if it's
  included), then delete (don't pass on) root automata if the analysis succeeds.

## 22/12/2016

* The `cat` tool generates a new file by directly writing the textual
  representation of a `ManifestFile` to disk. It seems to be valid to initialize
  a `Manifest` only given the file containing the textual representation.
* The logic to do this is pretty complex, but what we're going to want to do is
  hijack the process at the point at which we have a buffer containing a
  `ManifestFile` protobuf object.
* By doing this we then have a workflow:
    immutable Manifest --analysis-> ManifestFile --load--> new Manifest
* This is then composable for many passes in sequence, and `tesla-cat` shows how
  to generate a `ManifestFile` given constituent parts (Automata and Usages).
  From this we can then implement the recursive walk accept / reject style that
  will be used for the `acq_rel` analysis.
* Have replaced some parts of the `Manifest` code with uses of
  `std::unique_ptr`, as the legacy LLVM reimplementation has been deprecated. It
  would be worthwhile to fix up the rest of the code.
* Also another quality of life problem - there's a problem with how `llvm-lit`
  is running tests (to do with an output option), so probably wise to fix that
  before I do any major reshuffling of TESLA internals.
